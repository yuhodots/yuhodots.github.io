{"componentChunkName":"component---src-templates-post-js","path":"/deeplearning/25-06-01/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>ECCV 2024에 발표된 ObjectDrop 논문을 리뷰합니다.</p>\n</blockquote>\n<h3 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/00d58490775919f743b54c8f4085bf28/769f8/2025-06-01-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.578947368421055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACaElEQVQoz12R7UuTYRTG/Xf6Eonhh6KCIkEzVDK1LFGztPB1I82UMlnTarYwUWEa1kqdGTmbL9PNzcYzbbZwgalz6qamC7+0iSCo+/Vs6TIPnJv7us59X1znnIhAIMDOzg7B6OrRcubkaaSpSWQnJxIZfQJJaTkx8Qkci4rmaOTxUMbExqNqUXE9PQ1ZdVX4f1ArInjs7u6GiI52NZX5WcgvHKEyIYq7eddoVMqprcjnYUkWDyQ3KbmRTEVxNm9bm6gty0XdrBAFt/8XDOwJdmvayUpPoiLtLE/vpNAoL0XX2Up1aS51FbdQ1UpR1Ujoe1NHU8ML4mPPIy3KZ3t7+7DDv5a13e1cuXiKWmkmjyWZZF6O4ZmsnLyrcUgy4ijLSSIn+Ry3MxJQvVSI+BIqxaGW9y/B8Pt+456bYX7WyaJzhgXnNGsrS6x6XCL3g0Wx5nFNszTvZE7EZuMgEzZbeGRhhyEgktOzLkbH7AhWG+N6A/p+C+P2aYQJO8OjFvqNJjSfDGiHBEwWAZlCyQetLmzo3wz30ioIqNVttDU0UFx0j/sFJRj79Wi6NSjrn6NUPqG5pYV3HRrskw66RDGzxcpBjVDL+yFYx2h79Rp1o4qCQgmPqmSMmCy0tXeQmltIYmoKNaKrjq6PGExm5HX1dPfoDkoQEdzQxsYGm5ubOJ1OzOZRDMYR+gYGGBo28tX+jXHbF3p1vWjed9I3OID5s4VJx3f0wwYEwYrf78fn84WWExEEDoeDqakpXC4Xy8vLLCzM43Yvsrq6GsIrKyt4vb/wrnlZX1/np4iDfLDu8XjEt+5Qbm1t8QcyfXvqkhyKggAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/00d58490775919f743b54c8f4085bf28/15813/2025-06-01-1.webp 190w,\n/static/00d58490775919f743b54c8f4085bf28/1cdb2/2025-06-01-1.webp 380w,\n/static/00d58490775919f743b54c8f4085bf28/9046c/2025-06-01-1.webp 760w,\n/static/00d58490775919f743b54c8f4085bf28/c89f9/2025-06-01-1.webp 1140w,\n/static/00d58490775919f743b54c8f4085bf28/7afe4/2025-06-01-1.webp 1520w,\n/static/00d58490775919f743b54c8f4085bf28/7e82b/2025-06-01-1.webp 1924w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/00d58490775919f743b54c8f4085bf28/a2d4f/2025-06-01-1.png 190w,\n/static/00d58490775919f743b54c8f4085bf28/3f520/2025-06-01-1.png 380w,\n/static/00d58490775919f743b54c8f4085bf28/3c051/2025-06-01-1.png 760w,\n/static/00d58490775919f743b54c8f4085bf28/b5cea/2025-06-01-1.png 1140w,\n/static/00d58490775919f743b54c8f4085bf28/891d5/2025-06-01-1.png 1520w,\n/static/00d58490775919f743b54c8f4085bf28/769f8/2025-06-01-1.png 1924w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/00d58490775919f743b54c8f4085bf28/3c051/2025-06-01-1.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>여러 diffusion 기반의 editing 모델들은 최근에 정말 좋은 성능을 보이고 있지만, 물리적으로도 realistic한 이미지를 생성하는 것은 아직 쉽지 않습니다. 예를 들면 object removal 모델은 object에 의해 가려진 픽셀들을 대체해야 할 뿐만 아니라, object에 관련된 그림자(shadow)나 반사(reflection) 효과 또한 제거할 수 있어야 합니다. </p>\n<p>Diffusion-based inpainting이나 prompt-to-prompt 같은 self-supervised 방식의 이미지 편집 방법론들은 이런 점에서 한계를 가집니다. 이미 object가 있던  상태의 이미지 정보만 가지고 있기 때문에 counterfactual(반사실) image에 대한 정보가 부족하고, 따라서 이런 그림자나 반사 효과를 충분히 제거할 수 없습니다. </p>\n<p>따라서 본 논문은 잘 큐레이팅 된 \"counterfactual\"한 데이터셋에 대해 diffusion 모델을 학습시키는 접근법을 제안합니다. Counterfactual dataset은 다음의 pair로 구성된 데이터 셋을 의미합니다.</p>\n<ol>\n<li>A factual image depicting the scene</li>\n<li>A counterfactual image depicting the scene after an object change (adding/removing it)</li>\n</ol>\n<p>이 데이터셋은 실제 사진사가 scene에 있는 object를 변경해가며 만들게 됩니다. 그리고 이 방식이 object removal에 대해서 다양한, 처음보는 object에 대해서도 잘 동작한다는 것을 논문 내에서 보여줍니다. </p>\n<p>다만 object insertion은 object removal 보다 더 까다로운 task이기 때문에 더 많은 양의 데이터를 필요로 했고, 따라서 저자들은 2-step approach를 취합니다.</p>\n<ol>\n<li>Object removal model을 작은 counterfactual dataset 기반으로 학습</li>\n<li>Object removal model을 사용하여 large unlabeled image dataset 내에 물체들을 제거하여 synthetic dataset 생성</li>\n</ol>\n<p>이렇게 만들어진 large synthetic dataset으로 insertion model을 학습합니다. 이 방법을 저자들은 bootstrap supervision이라고 명시하고 있고, 결과적으로 EmuEdit, AnyDoor, Paint-by-Example 등의 최근 방법론 보다 더 좋다는 것을 보였습니다.</p>\n<h3 id=\"related-works\" style=\"position:relative;\"><a href=\"#related-works\" aria-label=\"related works permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Works</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ca565e58840491a01518ec5508c2dbf7/093ec/2025-06-01-2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.15789473684211%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABtElEQVQoz22Q70sTcRzH76/rUfioIAIRQyhIgoTo96gHrjVCsUbOVLotiEgMs3S5TZZOk9zmrd1N7+bd2nLSE6WD2rTdtlf3PbUn9YE37++D7/vF5/OWOp0OYpyW4/mXgsL9wVvc811haS1DbrfJesUmUdgnnKy6vod/RqMntMLHTJVWq+XlTjjSycO2bXTDwNBULj0fpX9shGeTYa4GBrg+2M+LxBrn5CcEU9PIbxa5MDzBg/k0+z9+/h/Ybrc9V1WF3svd9PadwReJ0jcS4HwwwNTqe17HAswkht0rNngVT5NStzg8+P0vUMhxjk7O5da5e3uAO9cuMptMsaB9J5YvM/u5yvicznL+Gzcjac7650h+Mmg2nb9AIYnjqdfrmJaFpuaZHA8RDj3C/zjIqe4uTvd0IS/EkZczxAubTL37wMOhUZ6+jLFn/zoCHnMkUarYrtFouAW3qVRMotEwE2NDRBOL+OaXuPE2RXYzjVmQKW5E2N3Z5mtlB7NcdXMHXl2CIVzSNM3tTSWbzaIoCrque5taVhl9S8fQDbZLJQyj5LqJZVoUi0Xvn+FKZAWjVqt5wD/qLtu1hy2N5AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/ca565e58840491a01518ec5508c2dbf7/15813/2025-06-01-2.webp 190w,\n/static/ca565e58840491a01518ec5508c2dbf7/1cdb2/2025-06-01-2.webp 380w,\n/static/ca565e58840491a01518ec5508c2dbf7/9046c/2025-06-01-2.webp 760w,\n/static/ca565e58840491a01518ec5508c2dbf7/c89f9/2025-06-01-2.webp 1140w,\n/static/ca565e58840491a01518ec5508c2dbf7/7afe4/2025-06-01-2.webp 1520w,\n/static/ca565e58840491a01518ec5508c2dbf7/c8acf/2025-06-01-2.webp 1930w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/ca565e58840491a01518ec5508c2dbf7/a2d4f/2025-06-01-2.png 190w,\n/static/ca565e58840491a01518ec5508c2dbf7/3f520/2025-06-01-2.png 380w,\n/static/ca565e58840491a01518ec5508c2dbf7/3c051/2025-06-01-2.png 760w,\n/static/ca565e58840491a01518ec5508c2dbf7/b5cea/2025-06-01-2.png 1140w,\n/static/ca565e58840491a01518ec5508c2dbf7/891d5/2025-06-01-2.png 1520w,\n/static/ca565e58840491a01518ec5508c2dbf7/093ec/2025-06-01-2.png 1930w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/ca565e58840491a01518ec5508c2dbf7/3c051/2025-06-01-2.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>논문에서는 4가지 정도의 related work를 소개합니다.</p>\n<ul>\n<li>Image inpaiting: 현실성 있는 object removal, 즉 그림자나 반사를 제거하는 것을 잘 못한다고 합니다.</li>\n<li>Shadow removal methods: 그림자 영역의 mask를 사용하여 그림자 지우는 것을 목표로 하는 task입니다. 본 연구는 모든 object와 관련된 영역(그림자와 반사 포함)을 제거하기 위해 그림자 영역이 아닌, object의 영역 mask만을 필요로 하기에, 이 점에서 본질적인 차이를 가집니다.</li>\n<li>General image editing model: 텍스트 기반 이미지 편집 모델을 의미합니다. Multi-modal LLM 또한 효과적이나, ObjectDrop 방법론이 더 우수하다고 말하고 있습니다.</li>\n<li>Object insertion: AnyDoor 라는 최신 방법론이 좋지만, object에 대한 identity 보존이 안되는 경우가 있다고 합니다. 반면에 ObjectDrop의 방법은 identity 보존도 잘 한다고 합니다.</li>\n</ul>\n<h3 id=\"self-supervision-is-not-enough\" style=\"position:relative;\"><a href=\"#self-supervision-is-not-enough\" aria-label=\"self supervision is not enough permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-Supervision is Not Enough</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/500ba82bb5c854abd0374dc7a679833a/3e992/2025-06-01-3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 60.526315789473685%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAADJUlEQVQozx2TWU+bVxCGv7+W26o3VSr1oqKRqiaNSkGqQipB5BQ3DiWBLIVQBxcUTArGBNI6KVtYDCnGIBuv32q84GBjg1cCgtYOeXrMSKPznpn3jObMIiHk9PSUUqHE+ceP/FerCVzk5OSEs7MzCgJXqtUGjSNxHh+9p16vUyqVKRRLfDg/F7x/qYl3DZFq9XO2Igazfj+72SLJZJYJOYbHSBNRk3gFDsdS7OeKLETjzOykUbQU3miMbeEPqglC6i4BOUm5eoJUr9XFJciw14mi6BRTSW7rUaaCAVK6gnPxDWtbXsrZLA4lzP1IgEQ4jNvnwbWySDQSIiC4q289HOTzSB/qNfZ2gyKbZd4ld/FV8jzLxTF2dOJ6EPf8FKqhUi3lMfR1gnqIdNJAVZbwB9fZe5fgMKMKn0pRlEE6Oz1DCUVRohp7qTTqjviOoqHrMdSQLOwy6USC7O4eIWFXk0mMqI6hxEgaCdSwxmEqTjZuUCqKgO8rFX4x3+dyUwt+zyazL/7kUlcf/S9cuEbGuPRpE45RJ7p/my9b2/mhpx/P6zmam03c/fkx81MunvY8ZGbcQS6zj5Tbz3Cz9VtuXruCb3UZa18vTZ23+H3cTp/lJ65c/oQZh52l+b+5/sVnDAjfH7YBfrz2NSMP7jFi7aOt+SrWbgsHos7Sfj6HY2yI185hBm39TL+a4rl7lu4Hd3gkgi+vLfDo127+ck0zuvgK6/gQneZ25lYWsA0/wWTuwLvpxmrt5R/PW6TMfpZnllYG2z7nSX8XEyMDdAyauW26jqWjhZ7OFsym73g5NozFegdTTxumtqv8dreNWze+ov3GN7hGH9Nr+R73yjzS0fExb17aWR+9x4bIYH1jDdvipMh4iGnnKHMOK7PjT/H5NlmdtrFkf8jkxHPck1Zcg11MTdhRIn7crjHRrABSYyMURSamRFDlKLKqElAVwuEgoVAI39YGoW0fcdFpLRomIcZDlmU0JcqOplzgRCJOrDE2hQLSschQVTUUoZFIBEUQVFlB0zQMwyAjCl0slaiKaSiVyxe4InBZaAOXGysoAh0cHl6s6v9rVBJ6mcbCCgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/500ba82bb5c854abd0374dc7a679833a/15813/2025-06-01-3.webp 190w,\n/static/500ba82bb5c854abd0374dc7a679833a/1cdb2/2025-06-01-3.webp 380w,\n/static/500ba82bb5c854abd0374dc7a679833a/9046c/2025-06-01-3.webp 760w,\n/static/500ba82bb5c854abd0374dc7a679833a/c89f9/2025-06-01-3.webp 1140w,\n/static/500ba82bb5c854abd0374dc7a679833a/7afe4/2025-06-01-3.webp 1520w,\n/static/500ba82bb5c854abd0374dc7a679833a/97599/2025-06-01-3.webp 1902w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/500ba82bb5c854abd0374dc7a679833a/a2d4f/2025-06-01-3.png 190w,\n/static/500ba82bb5c854abd0374dc7a679833a/3f520/2025-06-01-3.png 380w,\n/static/500ba82bb5c854abd0374dc7a679833a/3c051/2025-06-01-3.png 760w,\n/static/500ba82bb5c854abd0374dc7a679833a/b5cea/2025-06-01-3.png 1140w,\n/static/500ba82bb5c854abd0374dc7a679833a/891d5/2025-06-01-3.png 1520w,\n/static/500ba82bb5c854abd0374dc7a679833a/3e992/2025-06-01-3.png 1902w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/500ba82bb5c854abd0374dc7a679833a/3c051/2025-06-01-3.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>Diffusion-based inpainting이나 prompt-to-prompt 같은 attention-based 방식 등이 있었는데, 이러한 self-supervised 방법들은 아래와 같은 한계점을 가집니다.</p>\n<ul>\n<li>Segmentation mask를 넓게 설정한 경우: object가 아닌 다른 영역의 pixel을 지우게 되어, 원치 않는 영역도 pixel을 재생성하게 되고 이 과정에서 오류가 생깁니다.</li>\n<li>Segmentation mask를 너무 타이트 하게 설정한 경우: 그림자, 반사등 object와 관련된 정보를 지울 수 없습니다.</li>\n</ul>\n<h3 id=\"object-removal\" style=\"position:relative;\"><a href=\"#object-removal\" aria-label=\"object removal permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Removal</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8dbdc14eef222ff3af17df0bb428079e/3e992/2025-06-01-4.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.94736842105264%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACfklEQVQozzWRWU8TYRiF+9f8ASQkeqOJicaoidEbjHBhNGqUBKMBQxCBiBDAVEFUFgHZwUKhCy2ULtMpne7T6cy0hY4gIo8zo1yc77zvyXvOtzkOf/0kr2bQDkqUDZWj05pZK+SUNLKW5eC4wuGRTqUkUtX2qKpxszfQD35TUKvkijpZE0rZ4PgEHLKWYX7tK+tbs/gFF+uhRVa3vpNQQ/gT6zQ+aiIaWWJjdoTZxRk8vjmKpQxD44u4d1NEczVCks7g5DyJnIIjlYrR8uQe3wZe4fPP0NH7mq7eDsonMmld5E1/NynJy7prnsm5BbaCa+QLKV509jLvDqLUTilUjlnwbCMVSjjcmy4u153jfH0dI+ODdDt76Pv4jtngMBMeJ5397Qh7bjpbm7na2MT9njY0Lc+XBTebYYmpTZmFgML7iTmSOTPQ73dx61o9t29eYnpplI7+LnoG3/LNN8QnVx9tbzpIiKZ55TMTY05Wl0cpKhl++EKsBaL0TiUZWcniHJ9ESOdx7Eb8NN69wbOHDbg809x70EDzyycohxnkmkR6X6BqJBhovE7znRu0P39MOhPnwsUr9H0YQzuCjLmIxSPzU09wFLUCy5uLrHiWEbJhBof7zKs7zbAUaS1OtpKkup+ktLfMbnAcPbtBSc3ztKWVH94Q8v4fpGINSTGoGMc4FEVBTIjEhBih0A5SSiIajbK9vW1zLBZDFEUEQSAej9sciUTI5vLsJZP2jNWHw2FKJfMNZVm2zTs7O2ZgyK6DwaDdBwIBmy2caT6f3zafeawZr9dr6j4KhcK/E1rD1s5WoCVqmmZD13V7V4stWJqqqpTLZZvV/zOWbuUYhsFfJvKoD7bCa7YAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/8dbdc14eef222ff3af17df0bb428079e/15813/2025-06-01-4.webp 190w,\n/static/8dbdc14eef222ff3af17df0bb428079e/1cdb2/2025-06-01-4.webp 380w,\n/static/8dbdc14eef222ff3af17df0bb428079e/9046c/2025-06-01-4.webp 760w,\n/static/8dbdc14eef222ff3af17df0bb428079e/c89f9/2025-06-01-4.webp 1140w,\n/static/8dbdc14eef222ff3af17df0bb428079e/7afe4/2025-06-01-4.webp 1520w,\n/static/8dbdc14eef222ff3af17df0bb428079e/97599/2025-06-01-4.webp 1902w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/8dbdc14eef222ff3af17df0bb428079e/a2d4f/2025-06-01-4.png 190w,\n/static/8dbdc14eef222ff3af17df0bb428079e/3f520/2025-06-01-4.png 380w,\n/static/8dbdc14eef222ff3af17df0bb428079e/3c051/2025-06-01-4.png 760w,\n/static/8dbdc14eef222ff3af17df0bb428079e/b5cea/2025-06-01-4.png 1140w,\n/static/8dbdc14eef222ff3af17df0bb428079e/891d5/2025-06-01-4.png 1520w,\n/static/8dbdc14eef222ff3af17df0bb428079e/3e992/2025-06-01-4.png 1902w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/8dbdc14eef222ff3af17df0bb428079e/3c051/2025-06-01-4.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<h5 id=\"collecting-a-counterfactual-dataset\" style=\"position:relative;\"><a href=\"#collecting-a-counterfactual-dataset\" aria-label=\"collecting a counterfactual dataset permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Collecting a counterfactual dataset</h5>\n<p>데이터셋 생성을 위해서는 2500장의 counterfactual pair를 수집하였으며, 전문 사진사가 삼각대가 장착된 카메라를 사용하여 사진을 촬영하였습니다.</p>\n<ol>\n<li>Object <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span>를 포함하고 있는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>(fatual image)를 촬영합니다.</li>\n<li>카메라의 이동이나 빛의 변화, 그리고 다른 물체들의 이동 등을 제한한 상태에서 물리적으로 object <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span>를 제거합니다.</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mrow><mi>c</mi><mi>f</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">X_{cf}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>(counterfactual image)를 촬영합니다.</li>\n<li>Object <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span>에 대한 segmentation mask는 SAM 사용해서 생성하였습니다.</li>\n<li>최종 데이터셋은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>와 mask <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mo stretchy=\"false\">(</mo><mi>X</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">M(X)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span></span></span></span>, 그리고 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>X</mi><mrow><mi>c</mi><mi>f</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">X_{cf}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 구성합니다.</li>\n<li>2500장 중에서 100장을 test 데이터셋으로 설정합니다. </li>\n</ol>\n<h5 id=\"counterfactual-distribution-estimation\" style=\"position:relative;\"><a href=\"#counterfactual-distribution-estimation\" aria-label=\"counterfactual distribution estimation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Counterfactual distribution estimation</h5>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/be73f38d51258cd5b9c854832761affe/60c1e/2025-06-01-5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34.73684210526316%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAAA7ElEQVQoz11RWQqFQAzz/lcTBXfxQxDEXXHBfamk0sfwCiHTTtqpUXuehwT3fZMa53kyUAdEI3rcqb1gTR0wTRMdx8G8LAs1TUNVVdE8z7RtGwNnycES6LuuizQ0jeNI67oyt21LWZZRURTMQJ7nPBha1Muy5BwMPbiu629DXdfJcRyyLIsMwyDP8xioBUFAtm3zneu65Ps+IwxDSpKEz6ibpklRFH0byst4Aa9JiC8QAaqP/xrEz0PVVDTu+86AJ/BxGAYGfJWfpGqEYRdvGMcxAWma8obYFMDWyKXWdR0P7vuec3wZaqKHDou9e1cWnY296pQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/be73f38d51258cd5b9c854832761affe/15813/2025-06-01-5.webp 190w,\n/static/be73f38d51258cd5b9c854832761affe/1cdb2/2025-06-01-5.webp 380w,\n/static/be73f38d51258cd5b9c854832761affe/9046c/2025-06-01-5.webp 760w,\n/static/be73f38d51258cd5b9c854832761affe/c89f9/2025-06-01-5.webp 1140w,\n/static/be73f38d51258cd5b9c854832761affe/7afe4/2025-06-01-5.webp 1520w,\n/static/be73f38d51258cd5b9c854832761affe/f3af2/2025-06-01-5.webp 1866w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/be73f38d51258cd5b9c854832761affe/a2d4f/2025-06-01-5.png 190w,\n/static/be73f38d51258cd5b9c854832761affe/3f520/2025-06-01-5.png 380w,\n/static/be73f38d51258cd5b9c854832761affe/3c051/2025-06-01-5.png 760w,\n/static/be73f38d51258cd5b9c854832761affe/b5cea/2025-06-01-5.png 1140w,\n/static/be73f38d51258cd5b9c854832761affe/891d5/2025-06-01-5.png 1520w,\n/static/be73f38d51258cd5b9c854832761affe/60c1e/2025-06-01-5.png 1866w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/be73f38d51258cd5b9c854832761affe/3c051/2025-06-01-5.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>직접 제작한 counterfactual dataset에 대해, large scale의 diffusion model을 학습시켜 object removal 모델을 획득합니다.</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\tilde x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6678599999999999em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\">x</span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span></span></span></span>: latent representation counterfactual image</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>: latent representation of the image containing the object we want to remove</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span>: mask</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span>: timestemp</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span></span></span></span>: text prompt encoding</li>\n</ul>\n<p>이 때, 전통적인 inpainting 방식과는 다르게, masked pixel을 gray나 black pixel으로 대치하지 않았다고 합니다. 이러한 방식은 모델이 해당 mask 영역의 정보를 충분히 활용하는 것을 도와서 일부만 투명한 물체나 mask가 불충분한 케이스에 대해서 잘 대처할 수 있도록 도와주었다고 합니다.</p>\n<h5 id=\"advantages-over-video-supervision\" style=\"position:relative;\"><a href=\"#advantages-over-video-supervision\" aria-label=\"advantages over video supervision permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Advantages over video supervision</h5>\n<p>Video로부터 얻어진 supervision을 사용하는 것도 가능하지만, 이 경우에는 심각한 한계점을 지닌다고 논문에서 말하고 있습니다.</p>\n<ol>\n<li>Counterfactual dataset에서는 유일하게 바뀌는 것이 object이지만, video에서는 카메라 위치와 같은 다른 많은 특성이 바뀔 수 있습니다. 이는 object removal과 다른 특성 사이의 잘못된 상관관계를 만들 수 있다고 합니다.</li>\n<li>Video로 부터 데이터셋을 만드는 방식은 움직이는 object에서만 작동합니다. 그리고 이 방식은 움직이기 어려운 물체(heavy, large, immobile objects)에 대해서도 잘 일반화되고, 실제 성능도 더 좋다고 합니다.</li>\n</ol>\n<h3 id=\"object-insertion\" style=\"position:relative;\"><a href=\"#object-insertion\" aria-label=\"object insertion permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Insertion</h3>\n<p>ObjectDrop을 object removal task 뿐만 아니라 object insertion까지 확장할 수 있습니다.</p>\n<p>Object insertion은 object에 대한 이미지와 target image, 그리고 desired position에 대해서, 주어진 object가 포함된 target image가 어떻게 보일지를 예측하는 것이 목표입니다.</p>\n<p>저자들은 상대적으로 작은 규모의 counterfactual 데이터셋(2,500개 샘플)이 object removal에는 성공적이지만, object insertion 훈련에는 불충분한 데이터라고 가정했습니다. 따라서 데이터의 양을 늘리기 위해 새로운 합성 방식을 사용하였습니다.</p>\n<h5 id=\"bootstrapping-counterfactual-dataset\" style=\"position:relative;\"><a href=\"#bootstrapping-counterfactual-dataset\" aria-label=\"bootstrapping counterfactual dataset permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bootstrapping Counterfactual Dataset</h5>\n<ol>\n<li>위에 제시한 데이터셋을 통해 object removal model을 학습시킵니다.</li>\n<li>\n<p>Large external dataset에 대해서 합성 데이터셋을 만듭니다.</p>\n<ul>\n<li>Foreground detector 사용해서 object를 detect 합니다.</li>\n<li>Object removal model을 통해 scene에서 object와 shadow reflection을 제거합니다.</li>\n<li>다시 해당 이미지에 object 영역만 붙여넣습니다.</li>\n</ul>\n</li>\n<li>이 데이터셋을 통해 object insertion을 위한 diffusion model을 finetune 합니다.</li>\n</ol>\n<p>본 논문에서 이러한 방식을 bootstrap supervision이라고 부르고 있습니다.</p>\n<p>더 자세하게는, (1) 총 14M 이미지를 모은 뒤에 이중에서 700K 적절한 이미지를 골르고, (2) 이에 대해 object removal을 수행한 뒤 결과가 괜찮은 데이터를 350K 골랐다고 합니다. 이는 object removal 모델을 학습시키기 위해 사용했던 데이터셋(2500장) 보다 140배가 많은 양입니다.</p>\n<h5 id=\"diffusion-model-training\" style=\"position:relative;\"><a href=\"#diffusion-model-training\" aria-label=\"diffusion model training permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Diffusion Model Training</h5>\n<ul>\n<li>Object removal에 대해서는 Latent Diffusion Model 사용했는데 pre-trained inpainting model 사용했습니다.</li>\n<li>내부적으로 SDXL과 비슷한 구조로 가져갔습니다.</li>\n<li>Object insertion에 대해서는 pre-trained inpainting model을 사용하지 않았습니다.</li>\n<li>합성 데이터가 충분히 realistic하지 않기 때문에 insertion task에서는 합성 데이터를 pre-training에만 사용합니다</li>\n<li>마지막 단계에서는 직접 만든 (사진사가 촬영한) counterfactual 데이터셋으로 모델을 fine-tune 하였습니다.</li>\n</ul>\n<h3 id=\"experiments\" style=\"position:relative;\"><a href=\"#experiments\" aria-label=\"experiments permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiments</h3>\n<p>Object removal task에 대한 quantitative result와 user study 결과입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4c803e4f35bc998a957178089b2e77ee/769f8/2025-06-01-6.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.47368421052632%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABAElEQVQY022Q6YqDQBCE8/6PJogmXkFRPBOjmHii8apNdXB/LNvQtNMz/VnVp7ZtUVUVsixDnucoyxJpmso5jmO5ezweKIriN+/3u/Sez6fcszZNg23bcJrnGdM0YRgGqQQpiiJwVVURhiHO5zN834dt2wiCAIZh4Hq9grPjOMocv/d9xwl/guAkSbCuqyit61rgVMJKNYfS/0KAHOIDWoyiCLfbTRSxUvGxAiZ7/CF7zPIzV1YvzMv2BVLmsiwCvVwu0DRNquu6cBwHlmUJnGda13VdLNM6bRM6vd/YPhxg/wIZfd/DNE14nicLp2VW2uSyu64TAJP22aMrqj2CrB8FxsG78tL7jgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/4c803e4f35bc998a957178089b2e77ee/15813/2025-06-01-6.webp 190w,\n/static/4c803e4f35bc998a957178089b2e77ee/1cdb2/2025-06-01-6.webp 380w,\n/static/4c803e4f35bc998a957178089b2e77ee/9046c/2025-06-01-6.webp 760w,\n/static/4c803e4f35bc998a957178089b2e77ee/c89f9/2025-06-01-6.webp 1140w,\n/static/4c803e4f35bc998a957178089b2e77ee/7afe4/2025-06-01-6.webp 1520w,\n/static/4c803e4f35bc998a957178089b2e77ee/7e82b/2025-06-01-6.webp 1924w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/4c803e4f35bc998a957178089b2e77ee/a2d4f/2025-06-01-6.png 190w,\n/static/4c803e4f35bc998a957178089b2e77ee/3f520/2025-06-01-6.png 380w,\n/static/4c803e4f35bc998a957178089b2e77ee/3c051/2025-06-01-6.png 760w,\n/static/4c803e4f35bc998a957178089b2e77ee/b5cea/2025-06-01-6.png 1140w,\n/static/4c803e4f35bc998a957178089b2e77ee/891d5/2025-06-01-6.png 1520w,\n/static/4c803e4f35bc998a957178089b2e77ee/769f8/2025-06-01-6.png 1924w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/4c803e4f35bc998a957178089b2e77ee/3c051/2025-06-01-6.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>Object insertion에 대한 quantitative &#x26; qualitative result 입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e2ec595e57bee9dfe2e42ca08d2f308b/3707e/2025-06-01-7.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 73.68421052631578%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAAD/0lEQVQ4yyWU6VOTVxSH37+nM/3az7ZOa8dPrfaDUhewtVanVQkBFElCEFlC2LJIIFuzEEEkJnnfIGFJUIhopWGpbKIpUNGYBARFWinl6Wt6Z86d+5zfnbn3nHvuEba2tkilUqyurrLz/j3b2+9kfsnmmw0+jLW1LJlMmnQ6lePd3X9y+s7O+xyz9y+bmxvs7e3mUIgMD1CoUXJOU0abpQHRfg3RVkXsRiPhjhY6DOUErJVIrlrCPgNBew2is5pot5G+TpO8riXS0cCAT8/i44cIt8M9NF83c1ZbTqm6BEttFYpSJVe0ZRh11ei1KpTnz6MqVuTYVKNFU6JAry7G0liHQeaK0iKuXS5kdDiKEOwL81X+SfK+z8fW2cmz55vcefYCcSXN7EqWxOILopN/MDSRZG45zfTiKg8n5xkbn2J+KcXMUhZ/X4xOcZDs5juEDq8H5Zk8Kq8osVjtjIzeZX1nD0kSCQVDRIdjvP17l1BIRBQl7t6LsfnuL6SwRFiSiMdHeL3xBm+Hl4lEAsFmMnD24CdcOLwPtVqFvbUR28xjdG2NmPTXuG5uxutoQ1dRjNmgp93SjMNYSVO1nB5TA+1tRga62mipKpZDHkB4FI9Rf/EE7toS/B2ttNcUYY6IeH0mbhjLMdcUY9CpcRsr8Jk1OBrL0Kku4Gwopbu9CkeLBneLFo9Rw8LkCMLrzHP6Q52YzU2MDoaJD4Xl0Pw8XZxn6tEI0UiIYNDP3NwM0+MjxCIBgmIPz2T9ceI+0QGJQLCbuZkptt6+QUg+maVcVUhlxSWSKytY1zcYXV5iNjHG/ZEhvJ1e7o//ysR4nGi/SKvNRGI6wfTEGGOjURxeJ3FZT8iHJxd+R4j3BzBdVRC01hDudnJGLgNDXQXm0wewlhagzD+K6UoRhoIvMF/IQ/1TAa46DaYfvsSsOIbqbAFt2ks0ndzPpORGmF2Yx3uri0BvkP5IL+21V/EZ6on4HNwJ9GCor8PeXI/ottEnh97aqJNzqWfwpouIzCZ9HR5zA6FfWll+uoAw9NsUKk8ArTuAR86dtqaQEo+ZerGLm7fdqK9epNIoF7jTRJfM9U2XUDZUo7Va8IteqnRFVMsv3+S1Mrc4I3+9fonjP57mYnk5erkUjlw+xX5nC4eqFagVR/nu+AE+PXqYg4c+Q6s4womf8/no+Dk+/nwflSV5fHvqMPnFZXxz7GtiA36E5aUk94YHefAgzuBgH+0OC75uLz233IihW7hcNnweO/4uF729t7HJutMu304OWZL8WB1WXG47Pd1uksknCJlMllev0rlus7LyJy9fpEi9TMm+TM6/vv5atg3SmTWya+t82L8m+zLZ9Zy+vb39f9P5YPL0H6Gkhcg70aZlAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/e2ec595e57bee9dfe2e42ca08d2f308b/15813/2025-06-01-7.webp 190w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/1cdb2/2025-06-01-7.webp 380w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/9046c/2025-06-01-7.webp 760w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/c89f9/2025-06-01-7.webp 1140w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/7afe4/2025-06-01-7.webp 1520w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/6c20f/2025-06-01-7.webp 1878w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/e2ec595e57bee9dfe2e42ca08d2f308b/a2d4f/2025-06-01-7.png 190w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/3f520/2025-06-01-7.png 380w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/3c051/2025-06-01-7.png 760w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/b5cea/2025-06-01-7.png 1140w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/891d5/2025-06-01-7.png 1520w,\n/static/e2ec595e57bee9dfe2e42ca08d2f308b/3707e/2025-06-01-7.png 1878w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/e2ec595e57bee9dfe2e42ca08d2f308b/3c051/2025-06-01-7.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>\n<p>Bootstrap supervision의 효과를 figure에서 확인 가능합니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/fc1ce9bd4d436c7c023f1e17bedb4789/a8979/2025-06-01-8.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.05263157894738%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAACUElEQVQozw3R2UsTAACA8f0X9VQ9B2FBBZoHBeVEsEYDMxRT09TpDm3OzOnGFM/lMXELbYgXmy1kc6lz3rXpnIuQmu7INiLtIUICS5H48u2D3+MnWPDNMrdgY9ppwWIfZO2dg6W3E4w5XrHqn8a77MSzucKC24XLNYNneQbnmzFmnZP4Fu24nTbm5t3415b4Ho8iKDBmU9IiptOsJk16nrrm+1gGdCQpLpBZm4zBpEYzpqIotxC9RonFIEcsTEKvfMy0Po+8rGRKCx5h0hayE5hDkPPyLmnqS4g0Qq6XnEVcfg2JIoOEijNcfHKOTGkyVQNSOpt7GB/opb+1HGVFMTPmbkY0IuoVxRi7elDLxGxvrSIwrxipsUpQvVbSOqqid0RFu/kpunEldTYZlcMlWN9bMBoMDPY1MdjbjKauCku/htHuejTPqjGb2unveM4HnwfBmteLf32TTd9H5lwuvB4P/o0A8+4FNtb9BPxbhEJf6GuSM9xWzVCLDK0imxG9iqHOWhqlYqzdNYyeWmDFjqChsZY7qZcpK82nrLyI9LQrFOSKkCkk3ExJIDM9EYvNhr1Pjjb/Nj11BegqhORlJGLUltEmFyIRpdBU+QD/ohWB2z1Pl6EHx9QUDruD7t4XTEyMMTXlpExSTEurjk+fdzB1VNEuzzqdkYO85B45olt0qR5SnJtB6o2rNJRm4Z2fRHB0fMzJyT8OD/8Qj8fZ3/9BJBIlGAwSDkeIxb+xt7d/2iHCoW12oyGikRCx3QjRcJBY7CsHB7/4ffCT46O//Afxr7gxvgPFCAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/fc1ce9bd4d436c7c023f1e17bedb4789/15813/2025-06-01-8.webp 190w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/1cdb2/2025-06-01-8.webp 380w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/9046c/2025-06-01-8.webp 760w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/c89f9/2025-06-01-8.webp 1140w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/7afe4/2025-06-01-8.webp 1520w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/f13a9/2025-06-01-8.webp 1828w\"\n              sizes=\"(max-width: 760px) 100vw, 760px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/fc1ce9bd4d436c7c023f1e17bedb4789/a2d4f/2025-06-01-8.png 190w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/3f520/2025-06-01-8.png 380w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/3c051/2025-06-01-8.png 760w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/b5cea/2025-06-01-8.png 1140w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/891d5/2025-06-01-8.png 1520w,\n/static/fc1ce9bd4d436c7c023f1e17bedb4789/a8979/2025-06-01-8.png 1828w\"\n            sizes=\"(max-width: 760px) 100vw, 760px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/fc1ce9bd4d436c7c023f1e17bedb4789/3c051/2025-06-01-8.png\"\n            alt=\"img\"\n            title=\"img\"\n            loading=\"lazy\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n  </a>\n    </span></p>","tableOfContents":"<ul>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#introduction\">Introduction</a></li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#related-works\">Related Works</a></li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#self-supervision-is-not-enough\">Self-Supervision is Not Enough</a></li>\n<li>\n<p><a href=\"/MachineLearning/25-06-01-ObjectDrop/#object-removal\">Object Removal</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#collecting-a-counterfactual-dataset\">Collecting a counterfactual dataset</a></li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#counterfactual-distribution-estimation\">Counterfactual distribution estimation</a></li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#advantages-over-video-supervision\">Advantages over video supervision</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"/MachineLearning/25-06-01-ObjectDrop/#object-insertion\">Object Insertion</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#bootstrapping-counterfactual-dataset\">Bootstrapping Counterfactual Dataset</a></li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#diffusion-model-training\">Diffusion Model Training</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"/MachineLearning/25-06-01-ObjectDrop/#experiments\">Experiments</a></li>\n</ul>","frontmatter":{"path":"/deeplearning/25-06-01/","title":"Paper Review: ObjectDrop (ECCV 2024)","category":"Deep Learning","date":"2025-06-01"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}