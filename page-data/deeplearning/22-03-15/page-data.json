{"componentChunkName":"component---src-templates-post-js","path":"/deeplearning/22-03-15/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>관심 분야의 논문 리스트를 기록합니다. 최근에 읽은 논문은 핵심 내용을 세 줄 요약으로 추가하고 있습니다. 체크 표시가 되어있지 않은 논문들은 추후 다시 읽어 볼 필요가 있는 논문을 의미합니다.</p>\n</blockquote>\n<h3 id=\"few-shot-learning--meta-learning\" style=\"position:relative;\"><a href=\"#few-shot-learning--meta-learning\" aria-label=\"few shot learning  meta learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Few-Shot Learning / Meta-Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3157382.3157504\">Vinyals, Oriol, et al. \"Matching networks for one shot learning.\" NIPS 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v48/santoro16.pdf\">Santoro, et al. \"Meta-Learning with Memory-Augmented Neural Networks.\" ICML 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3294996.3295163\">Snell, Jake, Kevin Swersky, and Richard Zemel. \"Prototypical networks for few-shot learning.\" NIPS 2017.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v97/yoon19a.html\">Yoon, Sung Whan, Jun Seo, and Jaekyun Moon. \"TapNet: Neural network augmented with task-adaptive projection for few-shot learning.\" ICML 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v70/finn17a\">Finn, Chelsea, Pieter Abbeel, and Sergey Levine. \"Model-agnostic meta-learning for fast adaptation of deep networks.\" ICML 2017.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2006.08306\">Mukaiyama, Kei, Issei Sato, and Masashi Sugiyama. \"LFD-Protonet: prototypical network based on local fisher discriminant analysis for few-shot learning.\" arXiv preprint arXiv:2006.08306, 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1805.10002\">Liu, Yanbin, et al. \"Learning to propagate labels: Transductive propagation network for few-shot learning.\" ICLR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Edge-Labeling_Graph_Neural_Network_for_Few-Shot_Learning_CVPR_2019_paper.html\">Kim, Jongmin, et al. \"Edge-labeling graph neural network for few-shot learning.\" CVPR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/goldblum20a.html\">Goldblum, Micah, et al. \"Unraveling meta-learning: Understanding feature representations for few-shot tasks.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v119/xu20i.html\">Xu, Jin, et al. \"Metafun: Meta-learning with iterative functional updates.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3327546.3327622\">Finn, Chelsea, Kelvin Xu, and Sergey Levine. \"Probabilistic model-agnostic meta-learning.\" ICML 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content/WACV2021/html/Fortin_Towards_Contextual_Learning_in_Few-Shot_Object_Classification_WACV_2021_paper.html\">Fortin, Mathieu Page, and Brahim Chaib-draa. \"Towards Contextual Learning in Few-Shot Object Classification.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/bronskill20a.html\">Bronskill, et al. \"TaskNorm: Rethinking Batch Normalization for Meta-Learning.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1803.02999\">Nichol, Alex, Joshua Achiam, and John Schulman. \"On first-order meta-learning algorithms.\" arXiv preprint arXiv:1803.02999 (2018).</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=umIdUL8rMH\">Oh, Jaehoon, et al. \"BOIL: Towards Representation Change for Few-shot Learning.\" ICLR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3326943.3327010\">Oreshkin, Boris N., et al. \"Tadam: Task dependent adaptive metric for improved few-shot learning.\" NIPS 2018.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=HJcSzz-CZ\">Ren, Mengye, et al. \"Meta-Learning for Semi-Supervised Few-Shot Classification.\" ICLR 2018.</a></p>\n<ul>\n<li>Semi-supervised few-shot classification을 푸는데, 이 때 unlabeled data에 distractor(support set에서 주어지지 않았던 class로, 단순 SSL시 방해가 되는 novel class)가 존재하는 상황</li>\n<li>ProtoNet w. soft k-means / ProtoNet w. soft k-means w. a distractor clsuter / ProtoNet w. soft k-means and masking, 총 3개의 방법을 제안</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"incremental-learning--continual-learning\" style=\"position:relative;\"><a href=\"#incremental-learning--continual-learning\" aria-label=\"incremental learning  continual learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Incremental Learning / Continual Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://ieeexplore.ieee.org/abstract/document/8107520\">Li, Zhizhong, and Derek Hoiem. \"Learning without forgetting.\" IEEE transactions on pattern analysis and machine intelligence 40.12 (2017): 2935-2947.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://www.sciencedirect.com/science/article/pii/S0893608019300231\">Parisi, German I., et al. \"Continual lifelong learning with neural networks: A review.\" Neural Networks 113 (2019): 54-71.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/yoon20b.html\">Yoon, Sung Whan, et al. \"XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://papers.nips.cc/paper/2019/hash/e833e042f509c996b1b25324d56659fb-Abstract.html\">Ren, Mengye, et al. \"Incremental Few-Shot Learning with Attention Attractor Networks.\" NIPS 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Tao_Few-Shot_Class-Incremental_Learning_CVPR_2020_paper.html\">Tao, Xiaoyu, et al. \"Few-shot class-incremental learning.\" CVPR 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2007.04546\">Ren, Mengye, et al. \"Wandering within a world: Online contextualized few-shot learning.\" arXiv preprint arXiv:2007.04546, 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/5942\">Luo, Yadan, et al. \"Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks.\" AAAI 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.html\">Gidaris, Spyros, and Nikos Komodakis. \"Dynamic few-shot visual learning without forgetting.\" CVPR 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2103.04059\">Cheraghian, Ali, et al. \"Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://ojs.aaai.org//index.php/AAAI/article/view/7079\">Liu, Bing. \"Learning on the job: Online lifelong and continual learning.\" AAAI 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1606.04671\">Rusu, Andrei A., et al. \"Progressive neural networks.\" arXiv preprint arXiv:1606.04671 (2016).</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=Sk7KsfW0-\">Yoon, Jaehong, et al. \"Lifelong Learning with Dynamically Expandable Networks.\" ICLR. 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2010.15277\">Masana, Marc, et al. \"Class-incremental learning: survey and performance evaluation.\" arXiv preprint arXiv:2010.15277 (2020).</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"file:///C:/Users/ECE/Desktop/16334-Article%20Text-19828-1-2-20210518.pdf\">Mazumder, Pratik, Pravendra Singh, and Piyush Rai. \"Few-Shot Lifelong Learning.\" AAAI 2021.</a></p>\n<ul>\n<li>CEC와 동일하게 data-init을 사용하여 base, novel classifier 생성</li>\n<li>CE loss를 사용하지 않고 triplet loss, minimize cosine similarity loss(for prototype), regularization loss를 사용</li>\n<li>전체 weight 중에서 크기가 작은 10%만 골라서, 이를 novel sample에 대해서 fine-tuning 진행</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html\">Zhu, Kai, et al. \"Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://www.pnas.org/content/114/13/3521.short\">Kirkpatrick, James, et al. \"Overcoming catastrophic forgetting in neural networks.\" PNAS 2017.</a></p>\n<ul>\n<li>Fisher Information Matrix를 사용하여, parameter space 상에서 특정 covariance를 제약으로 parameter 학습이 이루어지도록 하는 알고리즘 (mahalanobis distance와 동일한 formulation)</li>\n<li>논문 설명 블로그 <a href=\"https://yukyunglee.github.io/Fisher-Information-Matrix/\">링크1</a>, <a href=\"https://nzer0.github.io/Fisher-Info-and-NLL-Hessian.html\">링크2</a></li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/357cfba15668cc2e1e73111e09d54383-Abstract.html\">Shi, Guangyuan, et al. \"Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima.\" NeurIPS 2021.</a></p>\n<ul>\n<li>Robust optimization과 관계가 깊은 논문. Figure 2만 봐도 논문이 말하고자 하는 내용은 파악 가능</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.html\">Cha, Hyuntak, Jaeho Lee, and Jinwoo Shin. \"Co2l: Contrastive continual learning.\" ICCV 2021.</a></p>\n<ul>\n<li>Asymmetric SupCon loss로 novel learning하고, self-supervised instance-wise relation distill(IRD)로 preserve knowledge</li>\n<li>Asymmetric SupCon: current task와 memory buffer를 둘 다 사용하지만, anchor로는 current task만 사용. 이 경우에 그냥 SupCon보다 효과 좋음</li>\n<li>IRD: reference(previous) model output과 동일해지도록 현재 모델 regulate (대상은 2N개 전부)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=gYgMSlZznS\">Hu, Dapeng, et al. \"How Well Does Self-Supervised Pre-Training Perform with Streaming ImageNet?.\" NeruIPS 2021.</a></p>\n<ul>\n<li>Self-supervised learning 방식으로 pre-training하면, streaming data에 대해서 joint training 만큼의 성능이 나온다는 것을 주장</li>\n<li>Pre-training은 MoCo-v2 protocol을 따르고, OpenSelfSup의 구현을 기반으로 하였음</li>\n<li>Streaming data의 distribution shift가 milld한 경우에는 joint training과 self-supervised pre-training의 성능이 거의 비슷하고, large distribution shift인 경우에는 MAS(memory aware synapse)와 data replay 방법을 사용하면 비슷함.</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=9Hrka5PA7LW\">Madaan, Divyam, et al. \"Rethinking the Representational Continuity: Towards Unsupervised Continual Learning.\" ICLR 2022.</a></p>\n<ul>\n<li>Label unannotated인 unsupervised continual learning(CURL)을 SimSiam과 Barlow Twining 알고리즘 사용하여 해결해보았더니 신기하게도 supervised continual learning보다 catastrophic forgetting에 robust 함</li>\n<li>Lifelong Unsupervised Mixup(LUMP)는 previous task(in memory buffer)와 current task 사이의 interpolate를 활용하는 방법이며, LUMP를 안 써도 잘하지만 LUMP 사용시 더 잘함</li>\n<li>UCL/SCL이 low layer에서는 similar하고 high layer에서는 dissimilar함. UCL의 loss landscape이 더 smooth 함.</li>\n<li>Test 단계에서 classifying은 KNN을 사용한다고 하는데, 어떻게 사용한건지 아직 제대로 살펴보진 않았음</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2112.04215.pdf\">Fini, Enrico, et al. \"Self-Supervised Models are Continual Learners.\" arXiv preprint arXiv:2112.04215, 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2202.08025\">Zhou, Minghao, et al. \"Diagnosing Batch Normalization in Class Incremental Learning.\" arXiv preprint arXiv:2202.08025, 2022.</a></p>\n<ul>\n<li>Training batch에 new class만 존재해야 better normalization &#x26; representation 학습 가능하지만, 이러면 모델이 BN discrepancy에 의해 편향됨. 이를 BN dilemma라고 함</li>\n<li>BN dilemma를 해소하기 위해서 BN trick(BNT) 방법을 제안</li>\n<li>EMA update는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>B</mi><mi>b</mi></msub></mrow><annotation encoding=\"application/x-tex\">B_b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> (balanced batch)로 하고, parameter update는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><msub><mi>B</mi><mi mathvariant=\"script\">M</mi></msub></mrow><annotation encoding=\"application/x-tex\">B_t, B_\\mathcal{M}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>를 가지고 EMA update 없이 joint training</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/forum?id=vwLLQ-HwqhZ\">Pham, Quang, Chenghao Liu, and H. O. I. Steven. \"Continual normalization: Rethinking batch normalization for online continual learning.\" ICLR 2022.</a></p>\n<ul>\n<li>Previous task에 대한 inference 상황에서 current task에 biased된 moments를 사용하게 되는 현상을 cross-task normalization effect라고 함</li>\n<li>BN을 continual learning task에 단순히 사용하는 경우에 이런 cross-task normalization effect가 존재하기 때문에, GN과 같이 cross-task normalization effect 없는 method도 같이 사용하자는 것이 논문의 아이디어. 즉, mini-batch와 spatial normalization 사이에 balancing이 continual learning 에서의 normalization에 중요하다고 주장</li>\n<li>SwithNorm이나 TaskNorm과 같이 BN, LN, IN, GN 등의 blending weight 형태보다 GN -> BN (=CN)의 형태가 더 좋다고 주장</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2201.12559\">Cha, Sungmin, et al. \"Task-Balanced Batch Normalization for Exemplar-based Class-Incremental Learning.\" arXiv preprint arXiv:2201.12559, 2022.</a></p>\n<ul>\n<li>Exemplar-based CIL에 대해, task-balaneced <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> 계산 방법과 affine transformation parameter를 덜 편향되게 하는 계산법을 제안함</li>\n<li>Task-balanced <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> calculation: current biased 되지 않도록 reshape과 repeat 연산을 사용한 새로운 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> 계산 방법 제안</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/forum?id=7pgFL2Dkyyy\">Skorokhodov, Ivan, and Mohamed Elhoseiny. \"Class Normalization for (Continual)? Generalized Zero-Shot Learning.\" ICRL 2021.</a></p>\n<ul>\n<li>ZSL에서 자주 사용되는 'normalize+scale'(NS) 방법과 'attributes normalization'(AN) 방법의 한계점을 언급하며 이를 개선한 CN 제안</li>\n<li>NS와 AN이 잘 되는 이유에 대한 informal한 분석/의견을 내놓으면서 이를 바탕으로 CN을 제안하는 과정이 매끄러움. 이 점 덕분에 accept이 되었다고 생각함</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/file/77ee3bc58ce560b86c2b59363281e914-Paper.pdf\">Zhu, Fei, et al. \"Class-Incremental Learning via Dual Augmentation.\" NeurIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2203.06953.pdf\">Zhou, Da-Wei, et al. \"Forward compatible few-shot class-incremental learning.\" CVPR 2022.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2306.13812.pdf\">Shibhansh Dohare, et al. \"Loss of Plasticity in Deep Continual Learning\"</a></p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=p_zknyfV9fY\">발표 영상 1</a>, <a href=\"https://www.youtube.com/watch?v=oA_XLqh4Das\">발표 영상 2</a></li>\n<li>기존 CL 연구들은 catastrophic forgetting 막는것만 집중했는데 사실 CL 세팅은 새로운 지식 학습하는 능력에도 영향을 미침</li>\n<li>CL에서 L2 regularization &#x26; <a href=\"https://arxiv.org/pdf/1910.08475.pdf\">shrink-and-perturb</a> 적절히 조정해주는게 plasticity(새로운 지식을 배우는 능력)에 도움됨</li>\n<li>CL 학습시 일부 dead neuron을 reinitialize해주는 방식 사용한게 도움됨 (continual backpropagation)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/hash/288cd2567953f06e460a33951f55daaf-Abstract.html\">Ash, Jordan, and Ryan P. Adams. \"On warm-starting neural network training.\" NeurIPS 2020.</a></p>\n<ul>\n<li>어떠한 지식을 배운 후, 해당 weight으로 유사한 지식을 학습하는 것을 warm start라고 하는데, 이는 (최종 training loss는 비슷하더라도) random initialzation으로 부터 다시 학습하는 것 보다 더 안 좋은 일반화 성능을 가짐. 본 논문에서는 이 현상이 왜 일어나는지 분석하고, 이를 극복할 수 있는 몇 가지 트릭을 제안 </li>\n<li>사전 실험: warm start의 generalization gap - 데이터 셋 절반을 미리 학습하고, 이에 대해 random init와 warm start 비교해봤을 때 warm start가 못함. Convection approach의 경우, 어떤 하이퍼파라미터 튜닝을 하던지 warm start가 항상 random init 보다 좋지 않음</li>\n<li>따라서 Shrink, Perturb, Repeat라는 방식 제안: (1) 이전 학습된 weight을 zero 방향으로 줄이고 (shrink), (2) paramter noise를 삽입. 즉, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>θ</mi><mi>i</mi><mi>t</mi></msubsup><mo>←</mo><mi>λ</mi><msubsup><mi>θ</mi><mi>i</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msubsup><mo>+</mo><msup><mi>p</mi><mi>t</mi></msup><mtext>, where </mtext><msup><mi>p</mi><mi>t</mi></msup><mo>∼</mo><mi mathvariant=\"script\">N</mi><mrow><mo fence=\"true\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo fence=\"true\">)</mo></mrow><mtext> and </mtext><mn>0</mn><mo>&lt;</mo><mi>λ</mi><mo>&lt;</mo><mn>1</mn><mtext>. </mtext></mrow><annotation encoding=\"application/x-tex\">\\theta_i^t \\leftarrow \\lambda \\theta_i^{t-1}+p^t \\text {, where } p^t \\sim \\mathcal{N}\\left(0, \\sigma^2\\right) \\text { and } 0&lt;\\lambda&lt;1 \\text {. }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05222em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.131103em;vertical-align:-0.276864em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.854239em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1031310000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9879959999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span></span></span></span><span class=\"mord text\"><span class=\"mord\">, where </span></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∼</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.14736em;\">N</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord text\"><span class=\"mord\"> and </span></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord text\"><span class=\"mord\">. </span></span></span></span></span></li>\n<li>해당 방법을 pre-training, continual active learning, batch online-learning 등에서 다양하게 활용 가능</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"domain-generalization\" style=\"position:relative;\"><a href=\"#domain-generalization\" aria-label=\"domain generalization permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Domain Generalization</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/bcb41ccdc4363c6848a1d760f26c28a0-Abstract.html\">Cha, Junbum, et al. \"Swad: Domain generalization by seeking flat minima.\" NIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Fan_Adversarially_Adaptive_Normalization_for_Single_Domain_Generalization_CVPR_2021_paper.html\">Fan, Xinjie, et al. \"Adversarially adaptive normalization for single domain generalization.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2012.04324.pdf\">Volpi, Riccardo, et al. \"Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=Phjti0QbkZ\">Zhou, Zhi, et al. \"ODS: Test-Time Adaptation in the Presence of Open-World Data Shift.\" ICML 2023.</a> </li>\n</ul>\n<h3 id=\"unsupervised-learning--self-supervised-learning\" style=\"position:relative;\"><a href=\"#unsupervised-learning--self-supervised-learning\" aria-label=\"unsupervised learning  self supervised learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Unsupervised Learning / Self-Supervised Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2006.07733\">Grill, Jean-Bastien, et al. \"Bootstrap your own latent: A new approach to self-supervised learning.\" NIPS 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html\">Kolesnikov, Alexander, Xiaohua Zhai, and Lucas Beyer. \"Revisiting self-supervised visual representation learning.\" CVPR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2102.06810\">Tian, Yuandong, Xinlei Chen, and Surya Ganguli. \"Understanding self-supervised Learning Dynamics without Contrastive Pairs.\" arXiv preprint arXiv:2102.06810, 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.05247?fbclid=IwAR3T_ZxXT0bmygQnpbWdPy_9_ilNR9nrCbALNgc6EffsXAevguFxQ_myPFE\">Kevin Lu, et al. \"Pretrained Transformers as Universal Computation Engines.\" arXiv preprint arXiv:2103.05247, 2021</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.01988\">Goyal, Priya, et al. \"Self-supervised Pretraining of Visual Features in the Wild.\" arXiv preprint arXiv:2103.01988, 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf\">Caron, Mathilde, et al. \"Unsupervised learning of visual features by contrasting cluster assignments.\" NeurIPS 2020.</a></p>\n<ul>\n<li>저자의 논문 설명 영상은 <a href=\"https://www.youtube.com/watch?v=7QmsTleiRLs\">이곳</a>에서 확인할 수 있음</li>\n<li>Key idea: Train an embedding with consistent cluster(prototypes) assignments between views of the same image</li>\n<li>Constraint: All prototypes are selected the same amount of time. 그래야 모든 sample이 하나의 cluster에만 할당되는 것을 방지할 수 있음. Objective 식에서는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>max</mi><mo>⁡</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">Q</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\max H(\\mathbf{Q})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span><span class=\"mclose\">)</span></span></span></span> 형태의 regularizer로 표현됨 (모든 cluster에 균등하게 할당되는 경우에 entropy기 maximize 되기 때문)</li>\n<li>Problem: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi mathvariant=\"bold\">Q</mi><mo>∈</mo><mi mathvariant=\"script\">Q</mi></mrow></msub><mi mathvariant=\"normal\">Tr</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><msup><mi mathvariant=\"bold\">Q</mi><mi mathvariant=\"normal\">⊤</mi></msup><msup><mi mathvariant=\"bold\">C</mi><mi mathvariant=\"normal\">⊤</mi></msup><mi mathvariant=\"bold\">Z</mi><mo fence=\"true\">)</mo></mrow><mo>+</mo><mi>ε</mi><mi>H</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">Q</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\max _{\\mathbf{Q} \\in \\mathcal{Q}} \\operatorname{Tr}\\left(\\mathbf{Q}^{\\top} \\mathbf{C}^{\\top} \\mathbf{Z}\\right)+\\varepsilon H(\\mathbf{Q})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"mop\"><span class=\"mop\">max</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.330277em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">Q</span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mathcal mtight\">Q</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">T</span><span class=\"mord mathrm\">r</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">⊤</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">C</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">⊤</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">Z</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ε</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span><span class=\"mclose\">)</span></span></span></span> </li>\n<li>Where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">Q</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Q}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8805499999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span></span></span></span> is the mapping matrix, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">C</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">C</span></span></span></span></span> are prototypes, and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">Z</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf Z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord mathbf\">Z</span></span></span></span> are feature vectors</li>\n<li>Solution: Sinkhorn-Knopp algorithm <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"bold\">Q</mi><mo>∗</mo></msup><mo>=</mo><mi mathvariant=\"normal\">Diag</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">u</mi><mo stretchy=\"false\">)</mo><mi>exp</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mfrac><mrow><msup><mi mathvariant=\"bold\">C</mi><mi mathvariant=\"normal\">⊤</mi></msup><mi mathvariant=\"bold\">Z</mi></mrow><mi>ε</mi></mfrac><mo fence=\"true\">)</mo></mrow><mi mathvariant=\"normal\">Diag</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold\">v</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{Q}^*=\\operatorname{Diag}(\\mathbf{u}) \\exp \\left(\\frac{\\mathbf{C}^{\\top} \\mathbf{Z}}{\\varepsilon}\\right) \\operatorname{Diag}(\\mathbf{v})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8831359999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">Q</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">D</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">a</span><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbf\">u</span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">exp</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0429199999999998em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">ε</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">C</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9270285714285713em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">⊤</span></span></span></span></span></span></span></span></span><span class=\"mord mtight\"><span class=\"mord mathbf mtight\">Z</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">D</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">a</span><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">v</span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>Where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">u</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44444em;vertical-align:0em;\"></span><span class=\"mord mathbf\">u</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">v</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44444em;vertical-align:0em;\"></span><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">v</span></span></span></span> are renormalization vectors in <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>K</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb R^K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span></span></span></span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi mathvariant=\"double-struck\">R</mi><mi>B</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbb R^B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span></span></span></span></span></span></span></span> respectively</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"semi-supervised-learning\" style=\"position:relative;\"><a href=\"#semi-supervised-learning\" aria-label=\"semi supervised learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Semi-Supervised Learning</h3>\n<ul>\n<li>Generative model: Gaussian mixture, Deep generative models</li>\n<li>Graph based: Label propagation</li>\n<li>Self-training: Pseudo labelling, Co-training</li>\n<li>Consistency regularization: Pi-model, Mean teacher</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.html\">Pham, Hieu, et al. \"Meta pseudo labels.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/ijcai05.pdf\">Zhou, Zhi-Hua, and Ming Li. \"Semi-supervised regression with co-training.\" IJCAI 2005.</a></p>\n<ul>\n<li>두 개의 kNN regressor를 사용하여 co-training 진행</li>\n<li>Sufficient and redundant view를 위해서 두 regressor의 metric은 p=2 Minkowsky와 p=5 Minkowsky로 서로 다르게 설정함 </li>\n<li>Key mechanism은 regression에서 confidence를 만들어내는 작업이었고, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>가 추가됨에 따라서 MSE가 얼마나 개선되는지를 계산하여(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mo>△</mo><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\vartriangle_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69986em;vertical-align:-0.15em;\"></span><span class=\"mrel\"><span class=\"mrel amsrm\">△</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>) 이 값이 제일 커지는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 대해 confidence가 높다고 판단하여 해당 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 pseudo label을 부여</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://par.nsf.gov/servlets/purl/10080181\">Jean, Neal, Sang Michael Xie, and Stefano Ermon. \"Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance.\" NIPS 2018.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2019/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html\">Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" NeurIPS 2019.</a></p>\n<ol>\n<li>Unlabel data에 대해서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 stochastic augmentation 수행 후 이를 모델에 입력</li>\n<li>모델이 뱉은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 probability 출력을 평균 낸 뒤에, temperature scailing을 통해 entropy minimization(sharpening) 수행. 그리고 이 값 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span></span></span></span>를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 unlabelled data가 공유</li>\n<li>배치 내에서 Labelled data는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>개, Unlabelled data는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">B*K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개 존재하게 됨</li>\n<li>총 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mo stretchy=\"false\">(</mo><mi>K</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">B*(K + 1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span> 개의 데이터를 섞은 뒤에 Labelled data <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>개, Unlabelled data <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">B*K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개와 각각 Mixup</li>\n<li>이 때, mixup <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>λ</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>λ</mi><mo separator=\"true\">,</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\lambda&#x27; = \\max(\\lambda, 1-\\lambda)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">λ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span></span></span></span>는 항상 0.5 이상이 나오도록 설정하여, labelled mixup data는 labelled data에 dominant 하고, unlabelled mixup data는 unlabelled data에 dominant 하도록 강제함</li>\n<li>Labelled mixup data로는 CE loss 계산, Unlabelled mixup data로는 Consistency loss 계산</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=HklkeR4KPB\">Berthelot, David, et al. \"ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring.\" ICLR 2020.</a></p>\n<ul>\n<li>Distribution Alignment: Unlabelled data의 예측 분포를 labelled data의 분포로 normalize. 즉, 기존 prediction <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span>에 unlabelled data 분포의 running average로 나누고 labelled data 분포의 running average로 곱해줌.</li>\n<li>Augmentation Anchoring</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf\">Sohn, Kihyuk, et al. \"Fixmatch: Simplifying semi-supervised learning with consistency and confidence.\" NeurIPS 2020.</a></p>\n<ul>\n<li>Labelled image: Weakly augmented image 사용해서 cross entropy</li>\n<li>Unlabelled image: Weakly augmented image에 대해서 threshold를 넘는 경우에 이 예측의 one-hot encoding을 strong augmented image의 pseudo label로써 사용. Threshold를 넘지 못하는 경우에는 loss에 포함시키지 않음</li>\n<li>원래는 temperatured scaling해서 pseudo label하였으나, temperature를 0으로 했을 때 잘 나왔다고 함 (이 경우 one-hot encoding과 동일)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.neurips.cc/paper/2019/hash/bf25356fd2a6e038f1a3a59c26687e80-Abstract.html\">Li, Xinzhe, et al. \"Learning to self-train for semi-supervised few-shot classification.\" NeurIPS 2019.</a></p>\n<ul>\n<li>Few-shot SSL (SSFSC)을 위해, unlabeled data에 pseudo-label(self-training)할 데이터 선정하는 방법 고안</li>\n<li>Noisy label에 의해 좋지 않은 방향으로 optimize되는 영향을 줄이기 위해서, soft weighting network(SWN) 모듈을 추가</li>\n<li>전체 과정은 아래와 같음</li>\n<li>[Cherry picking stage 1.] Pseudo labeling 할 unlabeled data를 class 마다 top Z개 씩 선정</li>\n<li>[Cherry picking stage 2.] SWN을 사용하여 선정된 unlabeled sample에 soft label 할당: top Z sample을 class-wise prototype과 concatenate하여 RelationNet 형태의 SWN에 넣고, output으로 나온 soft value 획득</li>\n<li>Soft-labeled pseudo samples와 support set 기반으로 모델 inner update</li>\n<li>Inner-updated된 모델에 대해서 query loss를 뽑고, 모델을 meta-update</li>\n<li>모델 초기 파라미터는 previous SOTA method인 MTL(meta transfer learning) pre-trained model을 그대로 사용하며, 해당 pre-trained model을 학습 시작점으로 사용. 그 뒤에 오로지 classifier weight만 meta-update함 (freezing the feature extractor)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=NI7moUOKtc\">Baixu Chen, et al. \"Debiased Self-Training for Semi-Supervised Learning.\" NeurIPS 2022.</a></p>\n<ul>\n<li>Data bias와 Training bias란?:</li>\n<li>Training bias를 줄이기 위한 방법: </li>\n<li>Data bias를 줄이기 위한 방법: </li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/20577\">Mingcai Chen, et al. \"Semi-supervised learning with multi-head co-training.\" AAAI 2022.</a></p>\n<ul>\n<li>2개 이상의 model(backbone)이 요구되는 기존 co-training 방식과 달리, 본 논문은 backbone은 하나로 두고 classification head만 여럿으로 두어 co-training 수행</li>\n<li>Weakly augmented sample을 여러 head에 전달 한 뒤에, 타겟이 되는 head를 제외한 나머지 head의 출력을 타겟 head의 pseudo-label로 사용</li>\n<li>그리고 Strong augmented sample을 타겟 head에 전달하여 나온 출력과 pseudo-label 사이의 cross-entropy 기반으로 loss 계산</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"open-set-recognition\" style=\"position:relative;\"><a href=\"#open-set-recognition\" aria-label=\"open set recognition permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Open-Set Recognition</h3>\n<ul>\n<li>Novelty Detection (ND) = One-Class Classification: Known class와 unknown class를 binary classification</li>\n<li>Open-Set Recognition (OSR): Known에 대한 closed-set classification과 unknown class detect를 동시에 수행</li>\n<li>Out-of-Distribution Detection (OOD): OSR과 유사하며, unknown class(outlier)가 더 넓은 도메인까지도 존재</li>\n<li>Anomaly Detection (AD): 학습 데이터가 모두 unlabeled. 즉, unsupervised learning 상황</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2105.14148\">Saito, Kuniaki, Donghyun Kim, and Kate Saenko. \"OpenMatch: Open-set Consistency Regularization for Semi-supervised Learning with Outliers.\" NeurIPS 2021.</a></p>\n<ul>\n<li>Open-set semi-supervised learning(OSSL) task를 풀기 위한 알고리즘</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=5hLP5JY9S2d\">Vaze, Sagar, et al. \"Open-Set Recognition: A Good Closed-Set Classifier is All You Need.\" ICLR 2022.</a></p>\n<ul>\n<li>Close-set classification을 잘하면 OSR도 잘한다는 것을 보인 논문 (이 두 performance 사이에 positive correlation이 존재한다)</li>\n<li>따라서 아주 기본적인 Maximum Softmax Probability (MSP) OSR 알고리즘만 사용해도, feature extractor 성능만 높으면 기존의 SOTA와 동일하거나 더 높은 성능을 얻을 수 있음</li>\n<li>해당 논문에서, softmax가 아닌 그 직전 값인 logit을 활용한 Maximum Logit Score (MLS) 방법과, Semantic Shift Benchmark (SSB) split도 추가적으로 제안하였음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.00953\">Chen, Guangyao, et al. \"Adversarial reciprocal points learning for open set recognition.\" TPAMI 2021.</a></p>\n<ul>\n<li>Porototype은 target class를 대표하는 벡터라면, reciprocal point는 non-target class를 대표하는 벡터임</li>\n<li>Unlabeled data가 존재할 수 있는 공간을 bounding 함</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"metric-learning\" style=\"position:relative;\"><a href=\"#metric-learning\" aria-label=\"metric learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Metric Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html\">Khosla, Prannay, et al. \"Supervised contrastive learning.\" NIPS 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2016/hash/6b180037abbebea991d8b1232f8a8ca9-Abstract.html\">Sohn, Kihyuk. \"Improved deep metric learning with multi-class n-pair loss objective.\" NIPS 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html\">He, Xinwei, et al. \"Triplet-center loss for multi-view 3d object retrieval.\" CVPR 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Zhirong, et al. \"Unsupervised feature learning via non-parametric instance discrimination.\" CVPR 2018.</a></li>\n</ul>\n<h3 id=\"normalization-methods\" style=\"position:relative;\"><a href=\"#normalization-methods\" aria-label=\"normalization methods permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Normalization Methods</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/2578eb9cdf020730f77793e8b58e165a-Abstract.html\">Lubana, Ekdeep S., Robert Dick, and Hidenori Tanaka. \"Beyond BatchNorm: towards a unified understanding of normalization in deep learning.\" NeurIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2103.01499.pdf\">Ergen, Tolga, et al. \"Demystifying batch normalization in relu networks: Equivalent convex optimization models and implicit regularization.\" ICLR 2022.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2101.08692.pdf\">Brock, Andrew, Soham De, and Samuel L. Smith. \"Characterizing signal propagation to close the performance gap in unnormalized ResNets.\" ICLR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v139/brock21a/brock21a.pdf\">Brock, Andy, et al. \"High-performance large-scale image recognition without normalization.\" ICML 2021.</a></li>\n</ul>\n<h3 id=\"novel-category-discovery\" style=\"position:relative;\"><a href=\"#novel-category-discovery\" aria-label=\"novel category discovery permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novel Category Discovery</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/1908.09884.pdf\">Han, Kai, Andrea Vedaldi, and Andrew Zisserman. \"Learning to discover novel visual categories via deep transfer clustering.\" ICCV 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/forum?id=BJl2_nVFPB\">Han, Kai, et al. \"Automatically Discovering and Learning New Visual Categories with Ranking Statistics.\" ICLR 2020.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://ieeexplore.ieee.org/abstract/document/9464163/\">Han, Kai, et al. \"Autonovel: Automatically discovering and learning novel visual categories.\" TPAMI 2021.</a></p>\n<ol>\n<li>Self-supervised pre-training on labelled and unlabelled data using RotNet loss (training <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>Supervised training on labelled data using CE loss (training the head <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>η</mi><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\eta^l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.043548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span> and the last micro-block of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>Training on pseudo-labelled data with ranking statisitics using BCE loss (training the head <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>η</mi><mi>u</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\eta^u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.858832em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span></span></span> and the last micro-block of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>2번과 3번 joint training 수행. 하지만 3번이 매 epoch마다 다르게 pseudo-labelled 되어 학습의 불안정을 유발하므로, MSE를 consistency cost로써 추가 (자세한 식은 논문 참고)</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=MEpKGLsY8f\">Chi, Haoang, et al. \"Meta discovery: Learning to discover novel classes given very limited data.\" ICLR 2022.</a></p>\n<ul>\n<li>Learning to discover novel classes(L2DNC) task에 대해서 이전 가정이 이론적으로 잘못되었다는 것을 증명하고, 이론적으로 가능한 L2DNC 상황을 재정립함. 이와 더불어 더 실생활과 관련있는 few novel observation 상황을 가정하여, L2DNCL task를 정의함.</li>\n<li>재정립한 L2DNCL이 meta-learning의 가정과 유사하여 MAML, ProtoNet의 아이디어를 차용한 MM, MP를 제안함.</li>\n<li>Meta-learning에 L2DNCL를 접목할 수 있도록 Clustering-rule-aware Task Sampler(CATA)를 제안함.</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Neighborhood_Contrastive_Learning_for_Novel_Class_Discovery_CVPR_2021_paper.html\">Zhong, Zhun, et al. \"Neighborhood Contrastive Learning for Novel Class Discovery.\" CVPR 2021.</a></p>\n<ul>\n<li>Ranking Statistics(RS) 방법에 NCL, SCL, HNG 총 세 개의 방법을 더 추가한 논문. 다만 ranking statistics를 사용하여 pseudo-labelling 하지 않고, cosine similarity 기준으로 pseudo-labelling 수행</li>\n<li>Neighborhood Contrastive Learning(NCL): Unlabelled dataset을 위한 loss. Self-supervised contrastive loss와 더불어, similarity가 높은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 개의 feature를 positive라고 labelling해서 contrastive loss를 추가적으로 계산. <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mi>n</mi><mi>c</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>α</mi><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>z</mi><mi>u</mi></msup><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mi>z</mi><mo>^</mo></mover><mi>u</mi></msup><mo fence=\"true\">)</mo></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>z</mi><mi>u</mi></msup><mo separator=\"true\">,</mo><msub><mi>ρ</mi><mi>k</mi></msub><mo fence=\"true\">)</mo></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\ell_{n c l}=\\alpha \\ell_{\\left(z^{u}, \\hat{z}^{u}\\right)}+(1-\\alpha) \\ell_{\\left(z^{u}, \\rho_{k}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord mtight\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1052em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">ρ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>Supervised Contrastive Learning(SCL): Labelled dataset을 위한 loss. 기존 supervised-contrastive loss와 동일</li>\n<li>Hard-Negative Generation(HNG): True negative(labelled dataset)와 easy negative(unlabelled dataset)를 interpolate 한 것 중에서 제일 유사도 높은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 개를 hard negative로 사용 </li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Bhattacharjee_Multi-class_Novelty_Detection_Using_Mix-up_Technique_WACV_2020_paper.html\">Bhattacharjee, Supritam, Devraj Mandal, and Soma Biswas. \"Multi-class novelty detection using mix-up technique.\" WACV 2020.</a></p>\n<ul>\n<li>Test query를 novel class와 mixup하면 output prediction 값이 낮고, base class와 mixup하면 output prediction 값이 특정 하나의 class에 대해 높을 것이라 가정</li>\n<li>Open-set recognition task에서 자주 사용되는 K개의 sigmoid classifier 사용</li>\n<li>Class 마다 N개의 exemplar 이미지를 가지고, 해당 이미지와 test query의 mixed 샘플 output 확인. N개의 output을 평균내어 이를 membership score라는 이름으로 정의</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2207.10659\">Joseph, K. J., et al. \"Novel Class Discovery without Forgetting.\" ECCV 2022.</a></p>\n<ul>\n<li>NCD, GCD의 advanced setting인 NCD without Forgetting을 제안함</li>\n<li>GCD 세팅과, base data training 이후에 base data에 대한 접근이 제한된다는 점이 차이점 (GCD 보다 더 어려운 task)</li>\n<li>Pseudo-latent, Mutual information based regularizer, Known Class Indentifier라는 방법들을 통해 NCDwF를 해결하는데, 아직 자세히 이해하지는 못했음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/ICCV2021/papers/Fini_A_Unified_Objective_for_Novel_Class_Discovery_ICCV_2021_paper.pdf\">Fini, Enrico, et al. \"A unified objective for novel class discovery.\" ICCV 2021.</a></p>\n<ul>\n<li>기존 multi-step approach와 달리 (Labeled data를 활용한 supervised learning 혹은, self-supervised pre-training 이후에 unlabeled data로 transfer clustering하는 접근 방법), 처음부터 모든 objective를 하나의 step에 합쳐 학습하는 방법을 제안하였고 좋은 성능을 기록함</li>\n<li>UNO 논문을 읽는 것 보다 SwAV 논문을 읽는 것이 UNO 알고리즘을 이해하는 데에 더 도움이 되니 참고하기</li>\n<li>논문 내에서 새롭게 제안하는 방법론이 없는데도 (task는 달라지긴 했지만) oral paper로 선정된 것이 조금 놀라움 (기존에 있는 방법들을 NCD에 적합하게 잘 엮은 논문임)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"generalized-category-discovery\" style=\"position:relative;\"><a href=\"#generalized-category-discovery\" aria-label=\"generalized category discovery permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generalized Category Discovery</h3>\n<ul>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2201.02609.pdf\">Vaze, Sagar, et al. \"Generalized Category Discovery.\" CVPR 2022.</a></p>\n<ul>\n<li>Generalized Category Discovery라는 task를 처음으로 정의한 논문</li>\n<li>Main algorithm: ViT DINO pretraining, Supervised contrastive learning + Self-supervised contrastive learning, Semi-supervised k-means clustering(using k-means++)의 순서로 알고리즘 구성</li>\n<li>Class number estimation method: Brent's method 사용</li>\n<li>Strong baselines: RS와 UNO에서 labelled dataset와 unlabelled dataset에 대한 classification head가 두 개로 나뉘어 존재하던 것을 하나로 합침. Backbone은 저자들이 제안한 ViT구조를 그대로 사용하였는데, backbone을 finetuning하는 것은 오히려 성능이 좋지 않아서, backbone은 freeze하고 classification head만 tuning하였음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2208.01898\">Fei, Yixin, et al. \"XCon: Learning with Experts for Fine-grained Category Discovery.\" arXiv preprint arXiv:2208.01898 (2022).</a></p>\n<ul>\n<li>Fine-grained dataset에 대해서, class-irrelevant cues(e.g. background, object pose) 위주로 clustering 되는 경향이 있음</li>\n<li>따라서 이를 해결하기 위해 dataset을 먼저 k-means clustering 하고(그러면 class-irrelevant cues 비슷한 것 끼리 얼추 모임), 이 data split에 대해 각각 contrastive learning을 수행하면 class-irrelevant cues로 인한 부정적인 영향을 줄일 수 있음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=O-r8LOR-CCA\">Cao, Kaidi, Maria Brbic, and Jure Leskovec. \"Open-world semi-supervised learning.\" ICLR 2022.</a></p>\n<ul>\n<li>Novel Category Discovery를 traditional SSL로 일반화한 Open-World Semi-Supervised Learning 세팅을 처음으로 제안 (Generalized Category Discovery와 동일한 세팅)</li>\n<li>Unlabeled data의 uncertainty를 기반으로 known(seen) class의 intra-class를 조절하면서 학습하는 end-to-end 알고리즘인 ORCA를 제안</li>\n<li>e.g., Unlabeled data의 uncertainty가 낮은 경우에, labeled data를 fully exploit</li>\n<li>이 과정을 통해 known class에 대한 discriminative representation learning이 novel class 대비 너무 빠르게 진행되지 않도록 강제함</li>\n<li>Supervised objective w. uncertainty adaptive margin, Pairwise objective, Regularization term, 총 3개의 주요 objectives로 이루어져있음</li>\n<li>Supervised objective w. uncertainty adaptive margin: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mi mathvariant=\"normal\">S</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msub><mo>∑</mo><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>∈</mo><msub><mi mathvariant=\"script\">Z</mi><mi>l</mi></msub></mrow></msub><mo>−</mo><mi>log</mi><mo>⁡</mo><mfrac><msup><mi>e</mi><mrow><mi>s</mi><mrow><mo fence=\"true\">(</mo><msubsup><mi>W</mi><msub><mi>y</mi><mi>i</mi></msub><mi>T</mi></msubsup><mo>⋅</mo><msub><mi>z</mi><mi>i</mi></msub><mo>+</mo><mi>λ</mi><mover accent=\"true\"><mi>u</mi><mo>ˉ</mo></mover><mo fence=\"true\">)</mo></mrow></mrow></msup><mrow><msup><mi>e</mi><mrow><mi>s</mi><mrow><mo fence=\"true\">(</mo><msubsup><mi>W</mi><msub><mi>y</mi><mi>i</mi></msub><mi>T</mi></msubsup><mo>⋅</mo><msub><mi>z</mi><mi>i</mi></msub><mo>+</mo><mi>λ</mi><mover accent=\"true\"><mi>u</mi><mo>ˉ</mo></mover><mo fence=\"true\">)</mo></mrow></mrow></msup><mo>+</mo><msub><mo>∑</mo><mrow><mi>j</mi><mo mathvariant=\"normal\">≠</mo><mi>i</mi></mrow></msub><msup><mi>e</mi><mrow><mi>s</mi><msubsup><mi>W</mi><msub><mi>y</mi><mi>j</mi></msub><mi>T</mi></msubsup><mo>⋅</mo><msub><mi>z</mi><mi>i</mi></msub></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\mathrm{S}}=\\frac{1}{n} \\sum_{z_i \\in \\mathcal{Z}_l}-\\log \\frac{e^{s\\left(W_{y_i}^T \\cdot z_i+\\lambda \\bar{u}\\right)}}{e^{s\\left(W_{y_i}^T \\cdot z_i+\\lambda \\bar{u}\\right)}+\\sum_{j \\neq i} e^{s W_{y_j}^T \\cdot z_i}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">S</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.7667970000000004em;vertical-align:-1.252512em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.40557em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.514285em;\"><span style=\"top:-2.19em;\"><span class=\"pstrut\" style=\"height:3.120285em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.600407142857143em;\"><span style=\"top:-3.618264285714286em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"minner mtight\"><span class=\"mopen sizing reset-size1 size6 mtight delimcenter\" style=\"top:0.125em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.97733em;\"><span style=\"top:-2.28333em;margin-left:-0.13889em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.97733em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.71472em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">⋅</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.04398em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">λ</span><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-2.56778em;\"><span class=\"pstrut\" style=\"height:2.56778em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span><span style=\"top:-2.56778em;\"><span class=\"pstrut\" style=\"height:2.56778em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord mtight\">ˉ</span></span></span></span></span></span></span><span class=\"mclose sizing reset-size1 size6 mtight delimcenter\" style=\"top:0.125em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mop mtight\"><span class=\"mop op-symbol small-op mtight\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1745899999999999em;\"><span style=\"top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\"><span class=\"mrel mtight\"><span class=\"mord vbox mtight\"><span class=\"thinbox mtight\"><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span></span><span class=\"mrel mtight\">=</span></span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.46032428571428574em;\"><span></span></span></span></span></span></span><span class=\"mspace mtight\" style=\"margin-right:0.19516666666666668em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.455242857142857em;\"><span style=\"top:-3.4552428571428573em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.698092857142857em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9773299999999999em;\"><span style=\"top:-2.28333em;margin-left:-0.13889em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5091600000000001em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.97733em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9091600000000001em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">⋅</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.04398em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.350285em;\"><span class=\"pstrut\" style=\"height:3.120285em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.514285em;\"><span class=\"pstrut\" style=\"height:3.120285em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.600407142857143em;\"><span style=\"top:-3.618264285714286em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"minner mtight\"><span class=\"mopen sizing reset-size1 size6 mtight delimcenter\" style=\"top:0.125em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0873300000000001em;\"><span style=\"top:-2.28333em;margin-left:-0.13889em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.03588em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.0873299999999997em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6833299999999998em;\"></span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.71472em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">⋅</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:-0.04398em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.65952em;\"></span><span class=\"mord mathnormal mtight\">i</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31472em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">λ</span><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-2.56778em;\"><span class=\"pstrut\" style=\"height:2.56778em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span><span style=\"top:-2.56778em;\"><span class=\"pstrut\" style=\"height:2.56778em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord mtight\">ˉ</span></span></span></span></span></span></span><span class=\"mclose sizing reset-size1 size6 mtight delimcenter\" style=\"top:0.125em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.252512em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> where uncertainty <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>u</mi><mo>ˉ</mo></mover><mo>=</mo><mfrac><mn>1</mn><mrow><mo fence=\"true\">∣</mo><msub><mi mathvariant=\"script\">D</mi><mi>u</mi></msub><mo fence=\"true\">∣</mo></mrow></mfrac><msub><mo>∑</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msub><mi mathvariant=\"script\">D</mi><mi>u</mi></msub></mrow></msub><mn>1</mn><mo>−</mo><msub><mo><mi>max</mi><mo>⁡</mo></mo><mi>k</mi></msub><mi mathvariant=\"normal\">Pr</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mi>Y</mi><mo>=</mo><mi>k</mi><mo>∣</mo><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\bar{u}=\\frac{1}{\\left|\\mathcal{D}_u\\right|} \\sum_{x_i \\in \\mathcal{D}_u} 1-\\max _k \\operatorname{Pr}\\left(Y=k \\mid X=x_i\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.56778em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.56778em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">u</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">ˉ</span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">∣</span></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.02778em;\">D</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285719em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">∣</span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.02778em;\">D</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285719em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.39981em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\"><span class=\"mop\">max</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mord mathrm\">P</span><span class=\"mord mathrm\">r</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></li>\n<li>Pairwise objective: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mi mathvariant=\"normal\">P</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>m</mi><mo>+</mo><mi>n</mi></mrow></mfrac><msub><mo>∑</mo><mstyle scriptlevel=\"1\"><mtable rowspacing=\"0.1em\" columnalign=\"center\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"1\" displaystyle=\"false\"><mrow><msub><mi>z</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msubsup><mi>z</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo>∈</mo><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"script\">Z</mi><mi>l</mi></msub><mo>∪</mo><msub><mi mathvariant=\"script\">Z</mi><mi>u</mi></msub><mo separator=\"true\">,</mo><msubsup><mi mathvariant=\"script\">Z</mi><mi>l</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo>∪</mo><msubsup><mi mathvariant=\"script\">Z</mi><mi>u</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo fence=\"true\">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable></mstyle></msub><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence=\"true\">⟨</mo><mi>σ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><msub><mi>z</mi><mi>i</mi></msub><mo fence=\"true\">)</mo></mrow><mo separator=\"true\">,</mo><mi>σ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><msubsup><mi>z</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">⟩</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{L}_{\\mathrm{P}}=\\frac{1}{m+n} \\sum_{\\substack{z_i, z_i^{\\prime} \\in\n\\left(\\mathcal{Z}_l \\cup \\mathcal{Z}_u, \\mathcal{Z}_l^{\\prime} \\cup \\mathcal{Z}_u^{\\prime}\\right)}}-\\log \\left\\langle\\sigma\\left(W^T \\cdot z_i\\right), \\sigma\\left(W^T \\cdot z_i^{\\prime}\\right)\\right\\rangle</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">P</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.5051999999999999em;vertical-align:-0.6552em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.6698000000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9642857142857143em;\"><span style=\"top:-2.9678571428571425em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.214em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"minner mtight\"><span class=\"mopen sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">∪</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285719em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.214em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">∪</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8278285714285715em;\"><span style=\"top:-2.214em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286em;\"><span></span></span></span></span></span></span><span class=\"mclose sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">)</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4642857142857143em;\"><span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6552em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">⟨</span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-2.441336em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">⟩</span></span></span></span></span></span></li>\n<li>Regularization term: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">R</mi><mo>=</mo><mi>K</mi><mi>L</mi><mrow><mo fence=\"true\">(</mo><mfrac><mn>1</mn><mrow><mi>m</mi><mo>+</mo><mi>n</mi></mrow></mfrac><msub><mo>∑</mo><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>∈</mo><msub><mi mathvariant=\"script\">Z</mi><mi>l</mi></msub><mo>∪</mo><msub><mi mathvariant=\"script\">Z</mi><mi>u</mi></msub></mrow></msub><mi>σ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>W</mi><mi>T</mi></msup><mo>⋅</mo><msub><mi>z</mi><mi>i</mi></msub><mo fence=\"true\">)</mo></mrow><mi mathvariant=\"normal\">∥</mi><mi mathvariant=\"script\">P</mi><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{R}=K L\\left(\\frac{1}{m+n} \\sum_{z_i \\in \\mathcal{Z}_l \\cup \\mathcal{Z}_u} \\sigma\\left(W^T \\cdot z_i\\right) \\| \\mathcal{P}(y)\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">R</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.25557em;vertical-align:-0.40557em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord mathnormal\">L</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">∪</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\" style=\"margin-right:0.07944em;\">Z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16454285714285719em;\"><span style=\"top:-2.357em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.40557em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∥</span><span class=\"mord\"><span class=\"mord mathcal\" style=\"margin-right:0.08222em;\">P</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span></span></span></span></li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2207.02261.pdf\">Rizve, Mamshad Nayeem, et al. \"OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning.\" ECCV 2022.</a></p>\n<ol>\n<li>Pairwise loss, cross entropy, rgularization 기반으로 novel class를 discovering하기 위한 OpenLDN 알고리즘 수행</li>\n<li>모든 파라미터를 다 초기화한 뒤에, OpenLDN으로 얻어낸 novel pseudo label 기반으로 closed-SSL 다시 수행 (MixMatch와 UDA 사용)</li>\n<li>Novel pseudo label이 학습이 진행됨에 따라 개선되도록 하기 위해서 iterative pseudo labeling 전략 사용</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2211.11727\">Xin Wen, et al. \"A Simple Parametric Classification Baseline for Generalized Category Discovery.\" Under review.</a></p>\n<ul>\n<li>GCD setting에서 기존 parametric classifier가 실패했던 이유를 찾아내고(less discriminative representation &#x26; unreliable pseudo-labeling strategy), 이를 기반으로 기존 알고리즘을 수정하여, parametric classifier로 SOTA 성능을 달성함</li>\n<li>결론적으로는, GCD의 representation learning 방식(self-supervised &#x26; superivsed contrastive learning)에서 \"parametric classification\" 관련 objective만 추가되었음. 그리고 non-parametric clustering은 사용하지 않음 (논문 내 section 4.2.만 읽으면 됨)</li>\n<li>실험에 앞서 발견한 인사이트들</li>\n<li>Classifier: class-mean classifier보다 parametric (linear, cosine) classifier가 더 좋음</li>\n<li>Representation: Projector를 거친 representation보다, backbone에서 나온 representation을 바로 사용하는 것이 더 좋음</li>\n<li>Decoupling(GCD) vs. Joint training(UNO): UNO의 성능이 낮았던 것은 UNO의 방식이 'self-label' 방식이었기 때문임. 'self-distill'(section 4.2.) 방식으로 수정하면 GCD보다 더 좋은 성능을 보임</li>\n<li>Self-distill: 2개의 different view에 대한 모델 예측을 출력한 뒤에, 하나의 출력에 sharpening을 가하여 다른 출력의 pseudo label로써 사용 (부가적으로 dead prototype을 만들지 않기 위한 entropy regularization term도 추가)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=yVcLmMW5ySI\">Sheng Zhan, et al. \"PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Novel Category Discovery.\" Under review.</a></p>\n<ul>\n<li>Multi-Prompt Clustering (MPC)를 활용하여 representation의 warm-up process 거침. <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msubsup><mi>L</mi><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi></mrow><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">S</mi></mrow></msubsup><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>γ</mi><msubsup><mi>L</mi><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi></mrow><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">U</mi></mrow></msubsup><mrow><mo fence=\"true\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"true\">‾</mo></mover><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">U</mi></mrow></msub><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">L_1(\\boldsymbol{x})=L_{\\mathrm{semi}}^{\\mathrm{CLS}}(\\boldsymbol{z})+\\gamma L_{\\mathrm{semi}}^{\\mathrm{CLU}}\\left(\\overline{\\boldsymbol{z}}_{\\mathrm{CLU}}\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\">x</span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.105833em;vertical-align:-0.264502em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.435498em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">s</span><span class=\"mord mathrm mtight\">e</span><span class=\"mord mathrm mtight\">m</span><span class=\"mord mathrm mtight\">i</span></span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">S</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.264502em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.105833em;vertical-align:-0.264502em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.435498em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">s</span><span class=\"mord mathrm mtight\">e</span><span class=\"mord mathrm mtight\">m</span><span class=\"mord mathrm mtight\">i</span></span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">U</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.264502em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6444400000000001em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span></span></span><span style=\"top:-3.5644400000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">U</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span> 식에서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>L</mi><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi></mrow><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">S</mi></mrow></msubsup><mo stretchy=\"false\">(</mo><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L_{\\mathrm{semi}}^{\\mathrm{CLS}}(\\boldsymbol{z})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.105833em;vertical-align:-0.264502em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.435498em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">s</span><span class=\"mord mathrm mtight\">e</span><span class=\"mord mathrm mtight\">m</span><span class=\"mord mathrm mtight\">i</span></span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">S</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.264502em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span><span class=\"mclose\">)</span></span></span></span>는 GCD의 contrastive learning과 동일하지만 매 layer마다 prompt weight이 추가되었다는 점만 다르고, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>L</mi><mrow><mi mathvariant=\"normal\">s</mi><mi mathvariant=\"normal\">e</mi><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi></mrow><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">U</mi></mrow></msubsup><mrow><mo fence=\"true\">(</mo><msub><mover accent=\"true\"><mi mathvariant=\"bold-italic\">z</mi><mo stretchy=\"true\">‾</mo></mover><mrow><mi mathvariant=\"normal\">C</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">U</mi></mrow></msub><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">L_{\\mathrm{semi}}^{\\mathrm{CLU}}\\left(\\overline{\\boldsymbol{z}}_{\\mathrm{CLU}}\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.105833em;vertical-align:-0.264502em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.435498em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">s</span><span class=\"mord mathrm mtight\">e</span><span class=\"mord mathrm mtight\">m</span><span class=\"mord mathrm mtight\">i</span></span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">U</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.264502em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord overline\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6444400000000001em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord boldsymbol\" style=\"margin-right:0.04213em;\">z</span></span></span></span></span><span style=\"top:-3.5644400000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"overline-line\" style=\"border-bottom-width:0.04em;\"></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathrm mtight\">C</span><span class=\"mord mathrm mtight\">L</span><span class=\"mord mathrm mtight\">U</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span>는 [CLU] prompt 대상으로 contrastive learning을 수행한다는 점이 특징임</li>\n<li>Semi-supervised affinity generration (SemiAG) 활용하여 pseudo-positive 선정을 위한 affinity graph 생성. Graph diffusion method를 사용하여 label을 각 노드로 퍼뜨리는데, 이 때 동일한 class 사이의 edge weight은 1, 다른 class 사이의 edge weight은 0으로 초기화 함</li>\n<li>모든 데이터셋에 대한 affinity graph를 매번 계산할 수 없으니 graph sampling 기법을 활용하며, 이렇게 샘플링된 graph를 활용하여 contrastive affinity learning (CAL) 수행</li>\n<li>Fine-grained dataset에 대한 성능이 매우 좋다는 점에 주목할만 함</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2212.00334.pdf\">Florent Chiaroni, et al., \"Mutual Information-based Generalized Category Discovery.\" Under review.</a></p>\n<ul>\n<li>Entropy <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">H</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathcal H(Y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathcal\" style=\"margin-right:0.00965em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mclose\">)</span></span></span></span>, Conditional entropy <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"script\">H</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mi mathvariant=\"normal\">∣</mi><mi>Z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathcal H(Y|Z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathcal\" style=\"margin-right:0.00965em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mclose\">)</span></span></span></span>, Cross entropy를 사용하여 모델을 튜닝</li>\n<li>Conditional entropy를 줄이는 것은 모델이 confident prediction을 출력하도록 유도하며, entropy term은 예측에 대한 class balance를 맞추는 데에 도움이 됨</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=oQjWltREeRA\">Bingchen Zhao, et al., \"Generalized Category Discovery via Adaptive GMMs without Knowing the Class Number.\" Under review.</a></p>\n<ul>\n<li>E-step: Semi-supervised k-means 수행하여 GMM의 class number와 prototype 추정</li>\n<li>M-step: 추정한 class number와 prototypes 기반으로 prototypical contrastive learning 수행</li>\n<li>M-step의 prototypical contrastive learning 식 자체는 prototype을 classifier로 사용하는 softmax cross-entropy와 다를 바 없어보임</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"data-augmentation\" style=\"position:relative;\"><a href=\"#data-augmentation\" aria-label=\"data augmentation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Augmentation</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=r1Ddp1-Rb\">Zhang, Hongyi, et al. \"mixup: Beyond Empirical Risk Minimization.\" ICLR 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Yun_CutMix_Regularization_Strategy_to_Train_Strong_Classifiers_With_Localizable_Features_ICCV_2019_paper.html\">Yun, Sangdoo, et al. \"Cutmix: Regularization strategy to train strong classifiers with localizable features.\" ICCV 2019.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.mlr.press/v97/verma19a.html\">Verma, Vikas, et al. \"Manifold mixup: Better representations by interpolating hidden states.\" ICML 2019.</a></p>\n<ul>\n<li>기존 Input-spcae mixup과 달리 itermediate layer의 representation을 mixup하는 방법</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mrow><mo fence=\"true\">(</mo><msub><mover accent=\"true\"><mi>g</mi><mo>~</mo></mover><mi>k</mi></msub><mo separator=\"true\">,</mo><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo fence=\"true\">)</mo></mrow><mo>:</mo><mo>=</mo><mrow><mo fence=\"true\">(</mo><msub><mo><mi mathvariant=\"normal\">Mix</mi><mo>⁡</mo></mo><mi>λ</mi></msub><mrow><mo fence=\"true\">(</mo><msub><mi>g</mi><mi>k</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>k</mi></msub><mrow><mo fence=\"true\">(</mo><msup><mi>x</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo separator=\"true\">,</mo><msub><mo><mi mathvariant=\"normal\">Mix</mi><mo>⁡</mo></mo><mi>λ</mi></msub><mrow><mo fence=\"true\">(</mo><mi>y</mi><mo separator=\"true\">,</mo><msup><mi>y</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left(\\tilde{g}_{k}, \\tilde{y}\\right):=\\left(\\operatorname{Mix}_{\\lambda}\\left(g_{k}(x), g_{k}\\left(x^{\\prime}\\right)\\right), \\operatorname{Mix}_{\\lambda}\\left(y, y^{\\prime}\\right)\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></li>\n<li>SVD 했을 때 eigenvalue가 전체적으로 작아지는 효과를 가짐. 즉, principal components 수가 작아지는 효과 (flattening)</li>\n<li>Flattening을 통해 eigenvalue가 전체적으로 작아지니 volume이 작아지며, compression은 information theory 관점에서 이론적, 실험적으로 generalization과 연관이 있어 장점을 가짐</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=vJb4I2ANmy\">Lim, Soon Hoe, et al. \"Noisy feature mixup.\" ICLR 2022.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/forum?id=g11CZSghXyY\">Wen, Yeming, et al. \"Combining Ensembles and Data Augmentation Can Harm Your Calibration.\" ICLR 2021.</a></li>\n</ul>\n<h3 id=\"object-detection\" style=\"position:relative;\"><a href=\"#object-detection\" aria-label=\"object detection permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Detection</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2010.04159\">Zhu, Xizhou, et al. \"Deformable DETR: Deformable Transformers for End-to-End Object Detection.\" ICLR 2021.</a> </li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58452-8_13\">Carion, Nicolas, et al. \"End-to-end object detection with transformers.\" ECCV  2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://openaccess.thecvf.com/content_iccv_2017/html/Dai_Deformable_Convolutional_Networks_ICCV_2017_paper.html\">Dai, Jifeng, et al. \"Deformable convolutional networks.\" ICCV 2017.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Tian_FCOS_Fully_Convolutional_One-Stage_Object_Detection_ICCV_2019_paper.html\">Tian, Zhi, et al. \"Fcos: Fully convolutional one-stage object detection.\" ICCV 2019.</a></p>\n<ul>\n<li>Object detection을 per-pixel prediction으로 재정의함. 따라서, 모델 예측이 pixel 단위로 수행되며, pixel 단위로 class 예측과 bbox 예측(그리고 centerness 예측)을 뱉음. Per-pixel prediction으로 정의하다보니, regressor 학습하는데 있어서 매우 많은 forground sample을 사용하는 효과낼 수 있음</li>\n<li>FPN 사용하고, multi-level feature에 shared head 활용해서 예측 뱉음</li>\n<li>현재 픽셀이 물체 중심과 얼마나 가까운지 예측하는 centerness loss도 추가하여 학습. Inference time에서는 classification socre와 곱하여 자연적으로 low quality prediction을 걸러낼 수 있었고, 또한 이후에 NMS 까지 한번 더 거치면 최종 bbox 예측 얻을 수 있음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"image-segmentation\" style=\"position:relative;\"><a href=\"#image-segmentation\" aria-label=\"image segmentation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Segmentation</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html\">Zhi Tian, et al., \"Boxinst: High-performance instance segmentation with box annotations,\" CVPR 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/10000000_900554171201033_1602411987825904100_n.pdf?_nc_cat=100&#x26;ccb=1-7&#x26;_nc_sid=3c67a6&#x26;_nc_ohc=YLTtOW2cPwwAX_Yy2Sd&#x26;_nc_ht=scontent-ssn1-1.xx&#x26;oh=00_AfB4YsQnTr0-I00xt5Q9W1P6Qbe_M9ey4Y1zBP7vvmRbLA&#x26;oe=643500E7\">Meta AI Research, \"Segment Anything,\" 2023</a></p>\n<ul>\n<li>Image segmentation에 대한 foundation model 개발</li>\n<li>SAM은 interactive segmentation 방식(mask 수정을 사람이 반복적으로 가이딩 해주는 방법)과 automatic segmentation 방식(바로 segmentation 가능하지만 많은 양의 학습 데이터 필요한 방법)의 일반화 버전. 즉, 두 방식 모두 가능하다는 것</li>\n<li>Zero-shot instance segmentation 정량 평가에서는 ViTDet이 좋지만, 사람 평가에서는 SAM이 좋았음</li>\n<li>Task: Promptable segmentation (for pre-training): forground, background points / boxs, masks / free-form text 등에 대한 다양한 제안이 ambiguous하게 들어오더라도, 올바른(valid) segmentation mask를 최소 하나 이상 반환해야 하는 task</li>\n<li>Interactive segmentation 방식은 선행 논문들 참고</li>\n<li>Forground, background points: (x, y, fg/bg)</li>\n<li>Boxs, masks: (x1, y1, x2, y2)</li>\n<li>Free-form text: 아직 공개되지 않음</li>\n<li>Model: Segment Anything Model (SAM)</li>\n<li>Image encoder: MAE pre-trained ViT</li>\n<li>Prompt encoder: input points and boxes by positional encoding, free-form text with text encoder CLIP, and dense(mask) prompt are embedded by ConvNet and summed element-wise with the image embedding</li>\n<li>Mask decoder: a modification of a Transformer decoder block</li>\n<li>Resolving ambiguity: 애매한 prompt 대처할 수 있도록 multi-output mask 가지도록 모델 구조 수정함. 3개면 충분했고, 학습할 때 loss가 가장 작은 output만 backprop 했음</li>\n<li>Losses: linear combination of focal and dice loss 20:1 </li>\n<li>Data: Data engine and Dataset (SA-1B)</li>\n<li>Data engine (model-in-the-loop): 처음에는 publice segmentation dataset으로 학습 (1) model assist annotator (classic interactive segmentation setup) - (2) semi-automatic annotation - (3) fully automatic mask creation</li>\n<li>SA-1B: the largest ever segmentation dataset (400x more masks than any existing segmentation dataset)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58452-8_17\">Tian, Zhi, Chunhua Shen, and Hao Chen. \"Conditional Convolutions for Instance Segmentation.\" ECCV 202.</a></p>\n<ul>\n<li>MaskRCNN은 Fixed weights에 ROIs를 입력으로 줘서 mask 출력하는데, 만약 A, B라는 사람 instance가 매우 겹쳐진 위치에서 비슷한 특징을 가지고 있는 경우에 A에 대해 B를 배경으로 잡아야 하는데 이것 어려움.</li>\n<li>CondInst: (1) ROI crop나 feature alignment 없이 ConvNet으로만 구성됨. (2) Fixed weight이 아니라 dynamically genarated ConvNet이라서 mask head 매우 컴팩트하고 빠름</li>\n<li>작동 순서는 다음과 같음</li>\n<li>이미지 입력을 FPN에 넣어 multi-resolution feature를 뽑아냄</li>\n<li>Feature 기반으로 classification prediction과 filter parameter <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{x,y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>, 그리고 center-ness output, box output를 생성. 여기서 filter parameter는 1x1 8 channel conv이고 이게 3개(conv1, conv2, conv3)임. 사실 ROI 사용 안하니까 box head는 필요 없긴 한데, box head 기반으로 NMNS하면 inference time 줄어들어서 사용함</li>\n<li>Mask branch <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>F</mi><mtext>mask</mtext></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>H</mi><mo separator=\"true\">,</mo><mi>W</mi><mo separator=\"true\">,</mo><mi>C</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">F_\\text{mask} \\in \\mathbb R^{H,W,C}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">mask</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.08125em;\">H</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">C</span></span></span></span></span></span></span></span></span></span></span></span>에 대해 relative coord를 append한 뒤, 해당 mask feature를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{x,y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 기반의 mask ConvNet head에 입력으로 넣어줌. 이 때, mask feature는 image input resolution의 1/8. 그리고 conditioning된 filter의 개수만큼의 instance가 있다고 생각하면 됨 (MaskRCNN에서는 ROI box 개수가 instance의 수를 나타냄)</li>\n<li>Loss function으로는 FCOS loss와 Mask loss 사용</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"http://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.html\">Cheng, Bowen, Omkar Parkhi, and Alexander Kirillov. \"Pointly-supervised instance segmentation.\" CVPR 2022.</a></p>\n<ul>\n<li>BoxInst 같은 box-supervised method가 이미 존재하지만, 여전히 성능은 좋지 않음. 그렇다고 해서 fully-supervised 방식을 사용하기에는 cost가 너무 많이 듦</li>\n<li>따라서 저자들은 box-supervison과 더불어 point-supervision도 사용해보자는 의견을 제시하고, 이 때point-supervision을 box-supervision 기반으로 만드는 효율적인(빠른) 방법을 제안함</li>\n<li>먼저 작업자가 Bbox를 만들면, 여기서 랜덤하게 point가 찍힘</li>\n<li>이 점에 대해서 작업자가 foreground와 background 라벨링을 또 한 번 수행함</li>\n<li>이 작업은 instance당 15초 정도 소요됨. 즉, fully supervised 방식 대비 5배 정도 빠른 라벨링 가능</li>\n<li>그리고 이렇게 만든 point supervision이 다른 '모든' instance segmentation pipeline과 compatible 하도록 만들었음. 즉, 이 point supervision을 가지고 mask loss를 계산하는 방법을 고안하여 제안함</li>\n<li>예측은 기존 instance segmentation의 모델과 동일하게 수행한 다음,</li>\n<li>GT points에 대해서 loss 계산을 하는데, prediction points는 prediction mask들의 bilinear interpolation을 사용. 이 방법은 기존 instance segmentation 모델에 대해 구조상으로는 변경될 것이 따로 없어서 좋음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> Tianheng Cheng, et al. \"Boxteacher: Exploring high-quality pseudo labels for weakly supervised instance segmentation.\" CVPR 2023.</p>\n<ol>\n<li>Teacher, student 구조로 모델 학습시키는데(Backbone으로는 CondInst 활용), 이미지 입력에는 strong augmentation 적용함</li>\n<li>모든 모델 예측을 pseudo label로 사용하는게 아니라, box GT와 충분히 비슷하고(high IoU), 모델이 강한 확신 보이는(high confidence) 예측만 필터링해서 pseudo label로 사용</li>\n<li>추가적으로, 예측 noise 줄이는 loss 고안해서 적용</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> Ruihuang Li, et al. \"SIM: Semantic-aware Instance Mask Generation for Box-Supervised Instance Segmentation.\" CVPR 2023.</p>\n<ol>\n<li>Pre-trained instance segmentation model 구비 (CondInst and Mask2Former)</li>\n<li>Class-wise Prototypes과 similarity 측정해서 semantic mask 얻음</li>\n<li>Instance mask 얻음</li>\n<li>Semantic mask와 instance mask를 weighted averaging하여 pseudo mask 얻음</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Beomyoung Kim, et al. \"The Devil is in the Points: Weakly Semi-Supervised Instance Segmentation via Point-Guided Mask Representation.\" CVPR 2023.</p>\n<ol>\n<li>만약 dataset의 10%만 fully labeled 되어있다면, 나머지 90%는 point supervision을 부여함. 당연히 이 부분은 사람이 만들어야하지만, instance 하나 당 point 하나이기 때문에 cost는 적음</li>\n<li>(Step 1): Fully-labeled data로 먼저 Teacher network와 MaskRefineNet을 학습함. MaskRefineNet은 [Teacher의 mask 예측 / 이미지 / Instance Point]를 입력으로 받아서, mask 예측을 개선시키는 네트워크임. 즉, Point label을 사용해서 더 좋은 예측으로 mask를 업데이트!</li>\n<li>Teacher 학습시에는 데이터셋에 point supervision이 존재하지 않기 때문에, mask 예측의 center point를 입력 point로 사용</li>\n<li>Student 학습시에는 데이터셋에 point supervision이 존재하기 때문에 해당 point supervision 활용</li>\n<li>(Step 2): Teacher의 예측을, MaskRefineNet 기반으로 개선시킨 후에, 개선된 mask를 pseudo-label로 사용함</li>\n<li>이 외에도 adaptive strategy라는 pseudo label 좀 더 보완하는 방법도 추가 제안함</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"multi-modal-learning\" style=\"position:relative;\"><a href=\"#multi-modal-learning\" aria-label=\"multi modal learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-Modal Learning</h3>\n<ul>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2210.03347\">Lee, Kenton, et al. \"Pix2Struct: Screenshot parsing as pretraining for visual language understanding.\" arXiv preprint arXiv:2210.03347, 2022.</a></p>\n<ul>\n<li>Visually-Situated Language Understanding: Documents, tables, infographics, and user interfaces (UIs) are intended to be consumed holistically, without clear boundaries between textual and visual elements</li>\n<li>Visually-situated language understanding task와 관련하여 prior work 들의 방법이 너무 산재해 있었고 서로 모델 구조나, 접근법, 데이터 등이 크게 sharing 되지 않았음</li>\n<li>Pre-training: 본 논문은 '웹 페이지의 masked-screenshot을 input으로 받아 HTML을 예측하는 형태의 pre-training 방법'을 고안하여, general-purpose의 visually-situated language understanding model을 구축함</li>\n<li>Curriculum learning: 학습 초기 단계에서 아주 쉬운 parsing 문제(e.g., 글씨에 색깔만 입힌 HTML parsing)로 warm-up stage를 거치면 converge도 빠르고 fine-tuning 성능도 좋아짐 (Appendix D 참고)</li>\n<li>Transfer learning: ViT를 위한 새로운 fine-tuning 전략인 variable-resolution input representation을 제안. 일반적으로 ViT는 image patch를 뽑기 전에 pre-defined resolution으로 rescale을 하는데, 이 경우에 screenshot을 왜곡하거나 high resolution으로의 transfer learning에 방해가 될 것임. 따라서 저자들은 2d absolute positional embedding을 input patch와 같이 입력으로 제공하였음</li>\n<li>Architecture: image-encoder-text-decoder ViT</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Xiaoshuai Hao, et al. \"Mixgen: A new multi-modal data augmentation.\" WACV Workshop 2023.</p>\n<ul>\n<li>image는 interpolating, text는 concatenating</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Liu, Zichang, et al. \"Learning Multimodal Data Augmentation in Feature Space.\" ICLR 2023.</p>\n<ul>\n<li>Task Network, Augmentation Network라는 것 도입해서 learning 기반으로 multi-modal feature augmentation</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> So, Junhyuk, et al. \"Geodesic multi-modal mixup for robust fine-tuning.\" <em>arXiv preprint arXiv:2203.03897</em> (2022).</p>\n<ul>\n<li>CLIP의 임베딩이 text, image 서로 separated 되어있음. CLIP embedding을 분석하고, 문제를 해결한 첫 논문임</li>\n<li>발견: temperature를 높여서 학습하면 uniformity와 alignment measure는 좋아지는데, downstream task의 performance는 하락함</li>\n<li>이를 해결할 방법으로 geodesic multi-modal mixup (m2 mixup) 제안</li>\n<li>hard negative를 image text feature mixup 사용해서 만들고, 이를 contrastive loss 안에 삽입</li>\n<li>이 때, feature mixup(interpolation)을 hypersphere 상에서 수행하여서 geodesic mixup이라 이름 붙임</li>\n<li>text, timage emedding 사이의 alignment를 개선시키고 이를 통해 fine-tuning에서의 robustness를 얻음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"natural-language-processing\" style=\"position:relative;\"><a href=\"#natural-language-processing\" aria-label=\"natural language processing permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Natural Language Processing</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=cu7IUiOhujH\">Gunel, Beliz, et al. \"Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning.\" ICLR 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://aclanthology.org/2020.acl-main.45.pdf\">Li, Xiaoya, et al. \"Dice Loss for Data-imbalanced NLP Tasks.\" ACL 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://aclanthology.org/C18-1182.pdf\">Yadav, Vikas, and Steven Bethard. \"A Survey on Recent Advances in Named Entity Recognition from Deep Learning models.\" COLING 2018.</a></li>\n</ul>\n<h3 id=\"reinforcement-learning\" style=\"position:relative;\"><a href=\"#reinforcement-learning\" aria-label=\"reinforcement learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reinforcement Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/1611.05763.pdf\">Wang, Jane X., et al. \"Learning to reinforcement learn.\" arXiv preprint arXiv:1611.05763, 2016</a></li>\n</ul>\n<h3 id=\"implicit-neural-representation\" style=\"position:relative;\"><a href=\"#implicit-neural-representation\" aria-label=\"implicit neural representation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Implicit Neural Representation</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58452-8_24\">Mildenhall, Ben, et al. \"Nerf: Representing scenes as neural radiance fields for view synthesis.\" ECCV 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.html\">Martin-Brualla, Ricardo, et al. \"Nerf in the wild: Neural radiance fields for unconstrained photo collections.\" CVPR 2021.</a></li>\n</ul>\n<h3 id=\"neural-architecture-search\" style=\"position:relative;\"><a href=\"#neural-architecture-search\" aria-label=\"neural architecture search permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Neural Architecture Search</h3>\n<ul>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=S1eYHoC5FX\">Liu, Hanxiao, Karen Simonyan, and Yiming Yang. \"Darts: Differentiable architecture search.\" ICLR 2019.</a></p>\n<ul>\n<li>Neural Architecture Search (NAS) 연구에 대해, 기존에는 search space가 미분 불가능하다는 문제점 때문에 RL 기반으로만 연구가 진행었는데, DARTS는 search space를 미분 가능하게 정의하고 여기에 MAML의 최적화 방식과 동일한 bilevel optimization을 도입하여 gradient descent 기반의 NAS를 가능하도록 만들었음</li>\n<li>Differentiable archtecture search: 논문에서 정의한 bilevel optimization 식을 통한 가중치 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 최적화 수행</li>\n<li>Discretization step: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span>와 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 기반으로 필요 없는 operation edge 제거</li>\n<li>Retraining for the top- <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> strongest operations: 남은 operation edge에 대해 처음부터 다시 학습 수행</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"long-tailed-recognition\" style=\"position:relative;\"><a href=\"#long-tailed-recognition\" aria-label=\"long tailed recognition permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Long-Tailed Recognition</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=r1gRTCVFvB\">Kang, Bingyi, et al. \"Decoupling Representation and Classifier for Long-Tailed Recognition.\" ICLR 2020.</a></li>\n</ul>\n<h3 id=\"bayesian-deep-learning\" style=\"position:relative;\"><a href=\"#bayesian-deep-learning\" aria-label=\"bayesian deep learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bayesian Deep Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v48/gal16.html\">Gal, Yarin, and Zoubin Ghahramani. \"Dropout as a bayesian approximation: Representing model uncertainty in deep learning.\" ICML 2016.</a></li>\n</ul>\n<h3 id=\"deep-neural-architectures\" style=\"position:relative;\"><a href=\"#deep-neural-architectures\" aria-label=\"deep neural architectures permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deep Neural Architectures</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://www.cs.toronto.edu/~hinton/FFA13.pdf\">Geoffrey Hinton. \"The Forward-Forward Algorithm: Some Preliminary Investigations.\" (2022).</a></li>\n</ul>\n<h3 id=\"technical-report\" style=\"position:relative;\"><a href=\"#technical-report\" aria-label=\"technical report permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Technical Report</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2105.07576.pdf\">Wu, Yuxin, and Justin Johnson. \"Rethinking\" Batch\" in BatchNorm.\" arXiv preprint arXiv:2105.07576, 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1807.03341\">Lipton, Zachary C., and Jacob Steinhardt. \"Troubling trends in machine learning scholarship.\" arXiv preprint arXiv:1807.03341, 2018.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2204.03475.pdf\">Ridnik, Tal, et al. \"Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results.\" arXiv preprint arXiv:2204.03475 , 2022.</a></p>\n<ul>\n<li>새로운 방법을 제안하는 논문은 아니고 technical report에 가까움</li>\n<li>ImageNet dataset에 대해서, 어떤 모델 구조더라도 하이퍼파라미터 튜닝 없이 동일하게 적용할 수 있는 USI(Unified Scheme for ImageNet)을 제안. Knowledge distillation과 몇 가지 modern tricks를 사용하였고, 모든 모델에 대해서 previous SOTA를 넘었음</li>\n<li>TResNet-L 구조의 teacher model과 더불어 논문에서 제안하는 하이퍼파라미터를 사용하면, CNN, Transformer, Mobile-oriented, MLP-only 형태의 student 모델에 대해서 모두 성능이 개선된다고 함</li>\n<li>일반적인 knowledge distillation 형태(vanilla KD)와 동일하게, true label y에 대해서는 cross entropy loss를 사용하고, teacher label에 대해서는 temperature를 사용하여 soft label을 만든 뒤에 student prediction과 KLD를 계산함</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2207.09238.pdf\">Phuong, Mary, and Marcus Hutter. \"Formal Algorithms for Transformers.\" <em>arXiv preprint arXiv:2207.09238</em> (2022).</a></li>\n</ul>\n<h3 id=\"blog-posts--videos\" style=\"position:relative;\"><a href=\"#blog-posts--videos\" aria-label=\"blog posts  videos permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Blog Posts &#x26; Videos</h3>\n<ul>\n<li><a href=\"https://engineering.clova.ai/posts/2022/07/nsml-k8s-based-platform\">https://engineering.clova.ai/posts/2022/07/nsml-k8s-based-platform</a></li>\n<li><a href=\"https://www.slideshare.net/deview/224nsml-80881317\">https://www.slideshare.net/deview/224nsml-80881317</a></li>\n<li><a href=\"https://helloworld.kurly.com/blog/second-mlops\">https://helloworld.kurly.com/blog/second-mlops</a></li>\n<li><a href=\"https://yangoos57.github.io/blog/mlops/kubeflow/pipeline_using_kfp_sdk/\">https://yangoos57.github.io/blog/mlops/kubeflow/pipeline_using_kfp_sdk/</a></li>\n<li><a href=\"https://samsungsds.tistory.com/32\">https://samsungsds.tistory.com/32</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=EEsYbiqqcc0\">https://www.youtube.com/watch?v=EEsYbiqqcc0</a></li>\n<li><a href=\"https://engineering.linecorp.com/ko/blog/data-engineering-with-airflow-k8s-1\">https://engineering.linecorp.com/ko/blog/data-engineering-with-airflow-k8s-1</a></li>\n<li><a href=\"https://humbledude.github.io/blog/2019/07/12/airflow-on-k8s/\">https://humbledude.github.io/blog/2019/07/12/airflow-on-k8s/</a></li>\n</ul>","tableOfContents":"<ul>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#few-shot-learning--meta-learning\">Few-Shot Learning / Meta-Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#incremental-learning--continual-learning\">Incremental Learning / Continual Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#domain-generalization\">Domain Generalization</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#unsupervised-learning--self-supervised-learning\">Unsupervised Learning / Self-Supervised Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#semi-supervised-learning\">Semi-Supervised Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#open-set-recognition\">Open-Set Recognition</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#metric-learning\">Metric Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#normalization-methods\">Normalization Methods</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#novel-category-discovery\">Novel Category Discovery</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#generalized-category-discovery\">Generalized Category Discovery</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#data-augmentation\">Data Augmentation</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#object-detection\">Object Detection</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#image-segmentation\">Image Segmentation</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#multi-modal-learning\">Multi-Modal Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#natural-language-processing\">Natural Language Processing</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#reinforcement-learning\">Reinforcement Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#implicit-neural-representation\">Implicit Neural Representation</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#neural-architecture-search\">Neural Architecture Search</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#long-tailed-recognition\">Long-Tailed Recognition</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#bayesian-deep-learning\">Bayesian Deep Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#deep-neural-architectures\">Deep Neural Architectures</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#technical-report\">Technical Report</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#blog-posts--videos\">Blog Posts &#x26; Videos</a></li>\n</ul>","frontmatter":{"path":"/deeplearning/22-03-15/","title":"Deep Learning Paper List","category":"Deep Learning","date":"2022-03-15"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}