---
title: "Object Detection"
date: "23-06-06"
template: "post"
draft: true
path: "/deeplearning/23-06-06/"
description: "Deep learning ê¸°ë°˜ì˜ object detection ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ë¦¬ë·°í•©ë‹ˆë‹¤. Two-stage detectorì™€ one-stage detector ì•Œê³ ë¦¬ì¦˜ ì¤‘ì—ì„œ ì œì¼ ìœ ëª…í•œ ì•Œê³ ë¦¬ì¦˜ì„ ìœ„ì£¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤."
category: "Deep Learning"
thumbnail: "deeplearning"
---

> Deep learning ê¸°ë°˜ì˜ object detection ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ë¦¬ë·°í•©ë‹ˆë‹¤. Two-stage detectorì™€ one-stage detector ì•Œê³ ë¦¬ì¦˜ ì¤‘ì—ì„œ ì œì¼ ìœ ëª…í•œ ì•Œê³ ë¦¬ì¦˜ì„ ìœ„ì£¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.

### TODOs

ì•„ë˜ ì„¸ê°œ ì°¸ê³ í•˜ê¸°

1. https://www.youtube.com/watch?v=jqNCdjOB15s
2. https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/
3. https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/

### Preliminary

- Localization: Objectì˜ ìœ„ì¹˜ë¥¼ bouding box í˜•íƒœë¡œ ì•Œì•„ë‚´ëŠ” task
- Object detection: ì´ë¯¸ì§€ ë‚´ì— ë‹¤ìˆ˜ì˜ objectê°€ ì¡´ì¬í•  ë•Œ, ê°ê°ì˜ classë¥¼ ë§ì¶”ê³  localization í•˜ëŠ” task
- RoI: Region of Interest
- Region proposal: ë¬¼ì²´ê°€ ìˆì„ ê²ƒ ê°™ì€ ìœ„ì¹˜
  - Sliding window: ë‹¤ì–‘í•œ í¬ê¸°ì˜ windowë¥¼ ì´ë¯¸ì§€ ìƒì—ì„œ sliding í•˜ë©´ì„œ í•´ë‹¹ ìœ„ì¹˜ì— ë¬¼ì²´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•
  - Selective search: ì¸ì ‘í•œ region ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³ , ì ì  í° ì˜ì—­ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë°©ë²•
- Intersection of Union (IoU): ì˜ˆì¸¡ bboxì™€ ì •ë‹µ bboxê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨

$$
\text{IoU} = \frac{\text{ë‘ bboxì˜ êµì§‘í•©}}{\text{ë‘ bboxì˜ í•©ì§‘í•©}}
$$

```python
# Code by ChatGPT

def compute_iou(box, boxes):
    """
    Computes the IOU between a given box and a set of boxes.
    :param box: Numpy array with shape (4,) representing the coordinates of a bounding box.
    :param boxes: Numpy array with shape (N, 4) representing the coordinates of N bounding boxes.
    :return: Numpy array with shape (N,) containing the IOUs between the box and the N bounding boxes.
    """
    # Calculate coordinates of intersection boxes
    x1 = np.maximum(box[0], boxes[:, 0])
    y1 = np.maximum(box[1], boxes[:, 1])
    x2 = np.minimum(box[2], boxes[:, 2])
    y2 = np.minimum(box[3], boxes[:, 3])

    # Calculate area of intersection boxes and union boxes
    intersection = np.maximum(0.0, x2 - x1) * np.maximum(0.0, y2 - y1)
    area_box = (box[2] - box[0]) * (box[3] - box[1])
    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    union = area_box + area_boxes - intersection

    # Calculate IOU and return
    iou = intersection / union
    return iou
```

- Non-Maximum Suppression (NMS): ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë™ì¼í•œ classë¡œ ë¶„ë¥˜ë˜ë©´ì„œ ê²¹ì¹˜ëŠ” ê²½ìš°ì—ëŠ” í•˜ë‚˜ë¡œ(í˜¹ì€ ì¼ë¶€ë¡œ) bbox ì˜ˆì¸¡ì„ ì¤„ì´ëŠ” ë°©ë²•

```python
# Code by ChatGPT

def non_maximum_suppression(bounding_boxes, confidence_scores, overlap_threshold):
    """
    Implements Non-Maximum Suppression on a set of bounding boxes and corresponding confidence scores.
    :param bounding_boxes: Numpy array with shape (N, 4) representing the coordinates of the N bounding boxes.
    :param confidence_scores: Numpy array with shape (N,) representing the confidence scores for the N bounding boxes.
    :param overlap_threshold: Float representing the maximum allowed overlap between two bounding boxes.
    :return: List with the indices of the selected bounding boxes.
    """
    # Sort bounding boxes by their confidence scores (highest to lowest)
    sorted_indices = np.argsort(-confidence_scores)

    selected_indices = []
    while sorted_indices.size > 0:
        # Select bounding box with highest confidence score
        best_box_index = sorted_indices[0]
        selected_indices.append(best_box_index)

        # Compute the IOUs between the selected bounding box and the remaining boxes
        remaining_indices = sorted_indices[1:]
        overlaps = compute_iou(bounding_boxes[best_box_index], bounding_boxes[remaining_indices])

        # Discard boxes with IOU greater than overlap threshold
        non_overlapping_indices = np.where(overlaps <= overlap_threshold)[0]
        sorted_indices = remaining_indices[non_overlapping_indices]

    return selected_indices
```

##### Evaluation Metric

- Average Precision (AP@0.5): IoU 0.5 ì´ìƒì„ true positiveë¡œ ì¸ì‹
- 11ì  ë³´ê°„ë²•ê³¼ ëª¨ë“ ì  ë³´ê°„ë²• ê³„ì‚°ë²•

$$
\begin{aligned}
& A P_{11}=\frac{1}{11} \sum_{R \in\{0,0.1,0.2, \ldots, 0.9,1\}} P_{\text {interp }}(R) \\
& {P}_{\text {interp }}({R})=\max _{\widetilde{{R}}: \widetilde{{R}} \geq {{R}}} {P}(\widetilde{{R}})
\end{aligned}
$$

$$
\begin{aligned}
& {A P}_{\text {all }}=\sum_n\left({R}_{n+1}-{R}_{{n}}\right) {P}_{\text {interp }}\left({R}_{n+1}\right) \\
& {P}_{\text {interp }}\left({R}_{n+1}\right)=\max _{\widetilde{{R}}: \widetilde{{R}} \geq {R}_{n+1}} {P}(\widetilde{{R}})
\end{aligned}
$$

- AP@[.5:.05:.95]: AP@0.5, AP@0.55, ..., AP@0.95ì˜ ê°’ì„ ëª¨ë‘ ì¸¡ì •í•˜ì—¬ í‰ê· . ëª¨ë“ ì  ë³´ê°„ë²•ì„ ì´ìš©í•´ì„œ APë¥¼ êµ¬í•œ ê°’ì˜ í‰ê· , ì¦‰, Precision Recall Curveì˜ ì•„ë˜ ë©´ì ì„ ì˜ë¯¸

- mean Average Precision: ê¸°ë³¸ì ìœ¼ë¡œ precisionì€ í•˜ë‚˜ì˜ objectì— ëŒ€í•œ ê²€ì¶œì„ ì˜ë¯¸í•˜ë¯€ë¡œ, mAPëŠ” ê°ê°ì˜ classì— ëŒ€í•´ AP(AP@[.5:.05:.95])ë¥¼ ê³„ì‚°í•˜ê³  í‰ê· ì„ ì‚°ì¶œí–ˆë‹¤ëŠ” ì˜ë¯¸
  $$
  m A P=\frac{1}{N} \sum_{i=1}^N A P_i
  $$

![img](../img/23-06-03-1.png)

<center><p><i>Taken from https://cocodataset.org/#detection-eval</i></p></center>

- Macro: 'í‰ê· ì˜ í‰ê· 'ì„ êµ¬í•˜ëŠ” ë°©ë²•. macro_precision = (precision_1 + precision_2 + ... + precision_K) / K where K is the number of classes
- Micro: 'ì „ì²´ì˜ í‰ê· 'ì„ êµ¬í•˜ëŠ” ë°©ë²•. micro_precision = TP / (TP + FP)

### Two-Stage Detector

ì¼ë°˜ì ìœ¼ë¡œ localizationê³¼ classificationì„ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜í–‰. ë”°ë¼ì„œ ì†ë„ê°€ ëŠë¦¬ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ìŒ

![img](../img/23-06-03-2.png)

<center><p><i>Taken from  Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi.</i></p></center>

##### R-CNN[^1]

1. ì´ë¯¸ì§€ì— ëŒ€í•´ selective searchë¥¼ ì´ìš©í•˜ì—¬ ì•½ 2000ê°œì˜ RoI ì¶”ì¶œ
   - selective search: 
2. ê° RoIë“¤ì„ warping
   - warping: 
3. Warped imageì— ëŒ€í•´ CNNìœ¼ë¡œ feature ì¶”ì¶œ
4. Featureë¥¼ í™œìš©í•˜ì—¬, SVMìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡(i.e., {x, y, width, height})ì„ ìˆ˜í–‰

##### Fast R-CNN[^2]

1. ì´ë¯¸ì§€ì— ëŒ€í•´ selective searchë¥¼ ì´ìš©í•˜ì—¬ ì•½ 2000ê°œì˜ RoI ì¶”ì¶œ (R-CNNê³¼ ë™ì¼)
2. ì´ë¯¸ì§€ë¥¼ CNNì— í•œë²ˆë§Œ ë„£ì–´ feature mapì„ ì¶”ì¶œ
3. ê°ê°ì˜ RoIë¥¼ feature map dimensionìœ¼ë¡œ projection(RoI projection)
4. RoI pooling ìˆ˜í–‰: RoI ì˜ì—­ì˜ feature mapì— max-pooling ì ìš©
5. ìµœì¢… featureë¥¼ í™œìš©í•˜ì—¬ softmax layerìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡ì„ ìˆ˜í–‰

##### Faster R-CNN[^3]

ğŸ“`Multi-reference Detection (Anchors Boxes)`

1. ì´ë¯¸ì§€ë¥¼ CNNì— ë„£ì–´ feature mapì„ ì¶”ì¶œ
2. Feature mapì„ region proposal network(RPN)ìœ¼ë¡œ ë³´ë‚´, feature mapì— ëŒ€í•œ RoI ìƒì„±
3. RoI pooling ìˆ˜í–‰
4. ìµœì¢… featureë¥¼ í™œìš©í•˜ì—¬ softmax layerìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡ì„ ìˆ˜í–‰

- RPN
  - k ê°œì˜ ì•µì»¤ë°•ìŠ¤ë¥¼ ì´ìš©
  - sliding windowë¥¼ ê±°ì³ ê° ìœ„ì¹˜ì— regressionê³¼ classification ìˆ˜í–‰
  - ë‹¤ë§Œ ë¬¼ì²´ê°€ ìˆë‹¤ ì—†ë‹¤ë§Œ ì•Œë©´ ë˜ë¯€ë¡œ 2ê°œì— ëŒ€í•œ classification

##### Feature Pyramid Networks (FPN)[^4]

ğŸ“`Feature Fusion`

![img](../img/23-06-03-4.png)

<center><p><i>Taken from Tsung-Yi Lin, et al.</i></p></center>

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### Summary

|              | Conference   | Region proposal             | RoI pooling | Classification layer | Localization layer |
| ------------ | ------------ | --------------------------- | ----------- | -------------------- | ------------------ |
| R-CNN        | CVPR 2014    | Selective search (CPU)      |             | SVMs                 | Regressor          |
| Fast R-CNN   | ICCV 2015    | Selective search (CPU)      |             | Softmax              | Regressor          |
| Faster R-CNN | NeurIPS 2015 | Sliding window w. RPN (GPU) |             | Softmax              | Regressor          |
| FPN          |              |                             |             |                      |                    |

### One-Stage Detector

ì¼ë°˜ì ìœ¼ë¡œ localizationê³¼ classificationì„ ë™ì‹œì— ìˆ˜í–‰í•˜ê³ , ì†ë„ê°€ ë¹¨ë¼ ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì— í™œìš©í•˜ëŠ”ë°ì— ìš©ì´í•¨. íŠ¹íˆ DETRì€ end-to-end frameworkë¥¼ ì œì•ˆí•˜ì—¬ ë³µì¡í–ˆë˜ object detection ê³¼ì •ì„ ë‹¨ìˆœí™”í•¨

![img](../img/23-06-03-3.png)

<center><p><i>Taken from  Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi.</i></p></center>

##### YOLO[^5]

ğŸ“`Multi-resolution Detection`, `Hard-negative Mining`

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### RetinaNet[^7]

ğŸ“`Keypoint Based Detection`

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### DETR[^8]

ğŸ“`End to End Detection`, `Reference-free Detection`

![img](../img/23-06-03-5.png)

<center><p><i>Taken from Nicolas Carion, et al.</i></p></center>

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### Summary

|           | Conference | Region proposal | RoI pooling | Classification layer | Localization layer |
| --------- | ---------- | --------------- | ----------- | -------------------- | ------------------ |
| YOLO      |            |                 |             |                      |                    |
| RetinaNet |            |                 |             |                      |                    |
| DETR      |            |                 |             |                      |                    |

### References

[^1]:Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2014.
[^2]: Girshick, Ross. "Fast r-cnn." *Proceedings of the IEEE international conference on computer vision*. 2015.
[^3]: Ren, Shaoqing, et al. "Faster r-cnn: Towards real-time object detection with region proposal networks." *Advances in neural information processing systems* 28 (2015).
[^4]: Lin, Tsung-Yi, et al. "Feature pyramid networks for object detection." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2017.
[^5]: Redmon, Joseph, et al. "You only look once: Unified, real-time object detection." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016.
[^6]:Liu, Wei, et al. "Ssd: Single shot multibox detector." *Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part I 14*. Springer International Publishing, 2016.
[^7]: Lin, Tsung-Yi, et al. "Focal loss for dense object detection." *Proceedings of the IEEE international conference on computer vision*. 2017.
[^8]: Carion, Nicolas, et al. "End-to-end object detection with transformers." *Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part I 16*. Springer International Publishing, 2020.
[^9]: Zou, Zhengxia, et al. "Object detection in 20 years: A survey." *Proceedings of the IEEE* (2023).
[^10]: Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi. "Recent advances in deep learning for object detection." *Neurocomputing*396 (2020): 39-64.
