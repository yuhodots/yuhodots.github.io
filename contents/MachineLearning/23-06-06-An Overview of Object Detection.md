---
title: "An Overview of Object Detection"
date: "2023-06-06"
template: "post"
draft: true
path: "/deeplearning/23-06-06/"
description: "Deep learning ê¸°ë°˜ì˜ object detection ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ë¦¬ë·°í•©ë‹ˆë‹¤. Two-stage detectorì™€ one-stage detector ì•Œê³ ë¦¬ì¦˜ ì¤‘ì—ì„œ ìœ ëª…í•œ ì•Œê³ ë¦¬ì¦˜ë“¤ì„ ìœ„ì£¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤."
category: "Deep Learning"
thumbnail: "deeplearning"
---

> Deep learning ê¸°ë°˜ì˜ object detection ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•´ ë¦¬ë·°í•©ë‹ˆë‹¤. Two-stage detectorì™€ one-stage detector ì•Œê³ ë¦¬ì¦˜ ì¤‘ì—ì„œ ìœ ëª…í•œ ì•Œê³ ë¦¬ì¦˜ë“¤ì„ ìœ„ì£¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.

### Introduction

- Localization: Objectì˜ ìœ„ì¹˜ë¥¼ bouding box í˜•íƒœë¡œ ì•Œì•„ë‚´ëŠ” task
- Object detection: ì´ë¯¸ì§€ ë‚´ì— ë‹¤ìˆ˜ì˜ objectê°€ ì¡´ì¬í•  ë•Œ, ê°ê°ì˜ classë¥¼ ë§ì¶”ê³  localization í•˜ëŠ” task
- RoI: Region of Interest
- Region proposal: Objectê°€ ìˆì„ ê²ƒ ê°™ì€ ì˜ì—­ì„ ì œì•ˆ
  - Sliding window: ë‹¤ì–‘í•œ í¬ê¸°ì˜ windowë¥¼ ì´ë¯¸ì§€ ìƒì—ì„œ sliding í•˜ë©´ì„œ í•´ë‹¹ ìœ„ì¹˜ì— ë¬¼ì²´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•
  - Selective search: ì¸ì ‘í•œ region ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê³ , ì ì  í° ì˜ì—­ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë°©ë²•
- Localization layer: Bbox positionë¥¼ ì œì•ˆí•˜ëŠ” layerì´ê³  ì¼ë°˜ì ìœ¼ë¡œ regressor í™œìš©
- Classification layer: Objectì˜ classë¥¼ ì œì•ˆí•˜ëŠ” layer
- RoI pooling: ê° RoI ì˜ì—­ì— ëŒ€í•´ pooling ë°©ì‹ (e.g., max-pooling) ì ìš©í•´ì„œ NxN matrix ì¶”ì¶œ
  - mask R-CNNì—ì„œëŠ” RoI pooling ê°œì„ ì‹œí‚¨ RoIAlign layer í™œìš©í•¨

- IoU (Intersection of Union): ì˜ˆì¸¡ bboxì™€ ì •ë‹µ bboxê°€ ê²¹ì¹˜ëŠ” ë¹„ìœ¨

$$
\text{IoU} = \frac{\text{ë‘ bboxì˜ êµì§‘í•©}}{\text{ë‘ bboxì˜ í•©ì§‘í•©}}
$$

```python
# Code by ChatGPT

def compute_iou(box, boxes):
    """
    Computes the IOU between a given box and a set of boxes.
    :param box: Numpy array with shape (4,) representing the coordinates of a bounding box.
    :param boxes: Numpy array with shape (N, 4) representing the coordinates of N bounding boxes.
    :return: Numpy array with shape (N,) containing the IOUs between the box and the N bounding boxes.
    """
    # Calculate coordinates of intersection boxes
    x1 = np.maximum(box[0], boxes[:, 0])
    y1 = np.maximum(box[1], boxes[:, 1])
    x2 = np.minimum(box[2], boxes[:, 2])
    y2 = np.minimum(box[3], boxes[:, 3])

    # Calculate area of intersection boxes and union boxes
    intersection = np.maximum(0.0, x2 - x1) * np.maximum(0.0, y2 - y1)
    area_box = (box[2] - box[0]) * (box[3] - box[1])
    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    union = area_box + area_boxes - intersection

    # Calculate IOU and return
    iou = intersection / union
    return iou
```

- Non-Maximum Suppression (NMS): ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë™ì¼í•œ classë¡œ ë¶„ë¥˜ë˜ë©´ì„œ ê²¹ì¹˜ëŠ” ê²½ìš°ì—ëŠ” í•˜ë‚˜ë¡œ(í˜¹ì€ ì¼ë¶€ë¡œ) bbox ì˜ˆì¸¡ì„ ì¤„ì´ëŠ” ë°©ë²•

```python
# Code by ChatGPT

def non_maximum_suppression(bounding_boxes, confidence_scores, overlap_threshold):
    """
    Implements Non-Maximum Suppression on a set of bounding boxes and corresponding confidence scores.
    :param bounding_boxes: Numpy array with shape (N, 4) representing the coordinates of the N bounding boxes.
    :param confidence_scores: Numpy array with shape (N,) representing the confidence scores for the N bounding boxes.
    :param overlap_threshold: Float representing the maximum allowed overlap between two bounding boxes.
    :return: List with the indices of the selected bounding boxes.
    """
    # Sort bounding boxes by their confidence scores (highest to lowest)
    sorted_indices = np.argsort(-confidence_scores)

    selected_indices = []
    while sorted_indices.size > 0:
        # Select bounding box with highest confidence score
        best_box_index = sorted_indices[0]
        selected_indices.append(best_box_index)

        # Compute the IOUs between the selected bounding box and the remaining boxes
        remaining_indices = sorted_indices[1:]
        overlaps = compute_iou(bounding_boxes[best_box_index], bounding_boxes[remaining_indices])

        # Discard boxes with IOU greater than overlap threshold
        non_overlapping_indices = np.where(overlaps <= overlap_threshold)[0]
        sorted_indices = remaining_indices[non_overlapping_indices]

    return selected_indices
```

##### Evaluation Metric

- Average Precision (AP .5): IoU 0.5 ì´ìƒì„ true positiveë¡œ ì¸ì‹
- 11ì  ë³´ê°„ë²•ê³¼ ëª¨ë“ ì  ë³´ê°„ë²• ê³„ì‚°ë²•

$$
\begin{aligned}
& A P_{11}=\frac{1}{11} \sum_{R \in\{0,0.1,0.2, \ldots, 0.9,1\}} P_{\text {interp }}(R) \\
& {P}_{\text {interp }}({R})=\max _{\widetilde{{R}}: \widetilde{{R}} \geq {{R}}} {P}(\widetilde{{R}})
\end{aligned}
$$

$$
\begin{aligned}
& {A P}_{\text {all }}=\sum_n\left({R}_{n+1}-{R}_{{n}}\right) {P}_{\text {interp }}\left({R}_{n+1}\right) \\
& {P}_{\text {interp }}\left({R}_{n+1}\right)=\max _{\widetilde{{R}}: \widetilde{{R}} \geq {R}_{n+1}} {P}(\widetilde{{R}})
\end{aligned}
$$

- AP[.5:.05:.95]: AP .5, AP .55, ..., AP .95ì˜ ê°’ì„ ëª¨ë‘ ì¸¡ì •í•˜ì—¬ í‰ê· . ëª¨ë“ ì  ë³´ê°„ë²•ì„ ì´ìš©í•´ì„œ APë¥¼ êµ¬í•œ ê°’ì˜ í‰ê· , ì¦‰, Precision-Recall Curveì˜ ì•„ë˜ ë©´ì ì„ ì˜ë¯¸

- mean Average Precision: ê¸°ë³¸ì ìœ¼ë¡œ precisionì€ í•˜ë‚˜ì˜ objectì— ëŒ€í•œ ê²€ì¶œì„ ì˜ë¯¸í•˜ë¯€ë¡œ, mAPëŠ” ê°ê°ì˜ classì— ëŒ€í•´ AP[.5:.05:.95]ë¥¼ ê³„ì‚°í•˜ê³  í‰ê· ì„ ì‚°ì¶œí–ˆë‹¤ëŠ” ì˜ë¯¸
  $$
  m A P=\frac{1}{N} \sum_{i=1}^N A P_i
  $$

![img](../img/23-06-03-1.png)

<center><p><i>Taken from https://cocodataset.org/#detection-eval</i></p></center>

- Macro: 'í‰ê· ì˜ í‰ê· 'ì„ êµ¬í•˜ëŠ” ë°©ë²•. macro_precision = (precision_1 + precision_2 + ... + precision_K) / K where K is the number of classes
- Micro: 'ì „ì²´ì˜ í‰ê· 'ì„ êµ¬í•˜ëŠ” ë°©ë²•. micro_precision = TP / (TP + FP)

##### Feature Pyramid Networks (FPN)[^4]

Multi-resolution ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ object detection ì„±ëŠ¥ í–¥ìƒì„ ì´ë£¨ê³ ì í•˜ëŠ” ì—°êµ¬ë“¤ ë§ì•˜ëŠ”ë° FPNë„ ê·¸ ì¤‘ í•˜ë‚˜ì„. ë‹¤ì–‘í•œ object detection ëª¨ë¸ë“¤ì˜ backboneìœ¼ë¡œ í™œìš©ë˜ì–´ ì„±ëŠ¥ì„ ë†’ì—¬ì¤Œ

- Featurized image pyramid: ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ í¬ê¸°ë¡œ resize í•˜ì—¬ ê°ê° CNNì— í†µê³¼ì‹œì¼œ feature map íšë“í•˜ëŠ” ë°©ë²•. ë‹¹ì—°íˆë„ ë§¤ìš° ëŠë¦¼
- Single feature map: ê°€ì¥ ë§ˆì§€ë§‰ feature mapë§Œ ì˜ˆì¸¡ì— í™œìš©í•˜ë¯€ë¡œ ì‘ì€ objectì— ëŒ€í•œ ì •ë³´ ì˜ ì¡ì§€ ëª»í•  ê²ƒì„
- Pyramidal feature hierarchy: 
- Feature Pyramid Network (FPN): 

![img](../img/23-06-03-4.png)

<center><p><i>Taken from Tsung-Yi Lin, et al.</i></p></center>

- Bottom-up pathway in FPN: 
- Top-down pathway in FPN: 

### Two-Stage Detector

Region proposalsì„ ë¨¼ì € ìƒì„± í•œ ì´í›„ì— object classification and bbox regression ìˆ˜í–‰. ë”°ë¼ì„œ ì†ë„ê°€ ëŠë¦¬ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì¢‹ìŒ

![img](../img/23-06-03-2.png)

<center><p><i>Taken from  Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi.</i></p></center>

##### R-CNN[^1]

Abbreviation of 'Region-Based Convolutional Neural Networks'

1. ì´ë¯¸ì§€ì— ëŒ€í•´ selective searchë¥¼ ì´ìš©í•˜ì—¬ ì•½ 2000ê°œì˜ RoI ì¶”ì¶œ
   - Selective search: ìì„¸í•œ ì„¤ëª…ì€ [ì´ê³³](https://lilianweng.github.io/posts/2017-10-29-object-recognition-part-1/#selective-search) ì°¸ê³ 
2. ê° RoIë“¤ì„ warping (i.e., transforming image regions to a fixed size)
3. Warped imageì— ëŒ€í•´ CNNìœ¼ë¡œ feature ì¶”ì¶œ
4. Featureë¥¼ í™œìš©í•˜ì—¬, SVMìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡(i.e., {x, y, width, height})ì„ ìˆ˜í–‰

##### Fast R-CNN[^2]

1. ì´ë¯¸ì§€ì— ëŒ€í•´ selective searchë¥¼ ì´ìš©í•˜ì—¬ ì•½ 2000ê°œì˜ RoI ì¶”ì¶œ (*R-CNNê³¼ ë™ì¼*)
2. ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ CNNì— ë„£ì–´ feature mapì„ ì¶”ì¶œ. ì¦‰, ì…ë ¥ ì´ë¯¸ì§€ê°€ CNNì— í•œ ë²ˆë§Œ forwarding ë˜ì–´ë„ ë¨
3. RoI projection: ê°ê°ì˜ RoIë¥¼ feature map dimensionìœ¼ë¡œ projection
4. RoI pooling ìˆ˜í–‰: Feature mapì—ì„œì˜ ê° RoI ì˜ì—­ì— ëŒ€í•´ max-pooling ì ìš©í•´ì„œ NxN matrix ì¶”ì¶œ
5. ìµœì¢… featureë¥¼ í™œìš©í•˜ì—¬ softmax layerìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡ì„ ìˆ˜í–‰

##### Faster R-CNN[^3]

Prior worksì˜ region proposal ë°©ì‹ì´ bottleneckì´ì—ˆëŠ”ë°, RPNì„ í†µí•´ end-to-end í˜•íƒœì˜ êµ¬ì¡° ì œì•ˆí•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ

1. ì´ë¯¸ì§€ë¥¼ CNNì— ë„£ì–´ feature mapì„ ì¶”ì¶œ (Prior worksì™€ ë‹¬ë¦¬, region proposal í•˜ê¸° ì „ì— feature ë¶€í„° ë½‘ìŒ)
2. Feature mapì„ region proposal network(RPN)ìœ¼ë¡œ ë³´ë‚´ feature mapì— ëŒ€í•œ RoI ìƒì„±
   - RPNì€ ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ í˜•íƒœì˜ anchor boxesë¥¼ ì‚¬ìš©í•œ sliding window ë°©ì‹ ì‚¬ìš©
   - RPNì˜ final layerì—ëŠ” ë¬¼ì²´ê°€ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ íŒë‹¨í•˜ëŠ” 2-softmaxì™€, bbox ì œì•ˆí•˜ëŠ” regressorê°€ ì¡´ì¬
   - 2-softmaxì™€ regressor ouputì„ ê¸°ë°˜ìœ¼ë¡œ RoI ìƒì„±í•˜ê³  ì´ë¥¼ RoI pooling layerë¡œ ì „ë‹¬
3. RoI pooling ìˆ˜í–‰
4. ìµœì¢… featureë¥¼ í™œìš©í•˜ì—¬ softmax layerìœ¼ë¡œëŠ” classification, regressorë¡œëŠ” bbox ì˜ˆì¸¡ì„ ìˆ˜í–‰

##### Recap.

|              | Conference   | Region proposal             | Classification layer | Localization layer |
| ------------ | ------------ | --------------------------- | -------------------- | ------------------ |
| R-CNN        | CVPR 2014    | Selective search (CPU)      | SVMs                 | Regressor          |
| Fast R-CNN   | ICCV 2015    | Selective search (CPU)      | Softmax              | Regressor          |
| Faster R-CNN | NeurIPS 2015 | Sliding window w. RPN (GPU) | Softmax              | Regressor          |

### One-Stage Detector

Pre-generated region proposals ì—†ì´ object classification and bbox regression ìˆ˜í–‰

![img](../img/23-06-03-3.png)

<center><p><i>Taken from  Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi.</i></p></center>

##### YOLO[^5]

ğŸ“`Multi-resolution Detection`, `Hard-negative Mining`

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### RetinaNet[^7]

ğŸ“`Keypoint Based Detection`

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

##### DETR[^8]

ğŸ“`End to End Detection`, `Reference-free Detection`

![img](../img/23-06-03-5.png)

<center><p><i>Taken from Nicolas Carion, et al.</i></p></center>

- ì„¸ì¤„ ìš”ì•½ ì¶”ê°€í•˜ê¸°

### References

##### Blog Posts

- https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/
- https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/

##### Papers

[^1]:Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2014.
[^2]: Girshick, Ross. "Fast r-cnn." *Proceedings of the IEEE international conference on computer vision*. 2015.
[^3]: Ren, Shaoqing, et al. "Faster r-cnn: Towards real-time object detection with region proposal networks." *Advances in neural information processing systems* 28 (2015).
[^4]: Lin, Tsung-Yi, et al. "Feature pyramid networks for object detection." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2017.
[^5]: Redmon, Joseph, et al. "You only look once: Unified, real-time object detection." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016.
[^6]:Liu, Wei, et al. "Ssd: Single shot multibox detector." *Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part I 14*. Springer International Publishing, 2016.
[^7]: Lin, Tsung-Yi, et al. "Focal loss for dense object detection." *Proceedings of the IEEE international conference on computer vision*. 2017.
[^8]: Carion, Nicolas, et al. "End-to-end object detection with transformers." *Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part I 16*. Springer International Publishing, 2020.
[^9]: Zou, Zhengxia, et al. "Object detection in 20 years: A survey." *Proceedings of the IEEE* (2023).
[^10]: Wu, Xiongwei, Doyen Sahoo, and Steven CH Hoi. "Recent advances in deep learning for object detection." *Neurocomputing*396 (2020): 39-64.
